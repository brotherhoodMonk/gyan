Q-1. What Is Node.Js?

1. Node.js is a JavaScript runtime or platform which is built on Google Chrome’s JavaScript v8 engine.
This runtime allows executing the JavaScript code on any machine outside a browser.

2. Node.js is single-threaded, that implements a concurrency model based on an event loop.
 It doesn’t block the main thread  execution thread instead registers a callback which allows the application
 to continue.

3. It means Node.js can handle concurrent operations without creating multiple
threads of execution so can scale pretty well.

 Following are the areas where it’s perfect to use Node.js.
I/O bound Applications
Data Streaming Applications
Data Intensive Real-time Applications (DIRT)
JSON APIs based Applications
Single Page Applications
At the same time, it’s not suitable for heavy applications involving more of CPU usage.
===
event loop-
To handle the asynchronous nature of program, Node.js uses external “Queue” called as event queue
where it inserts the
callback of asynchronous code rather than pushing it into call stack .

Since that piece of code is not in call stack, node runtime will not execute it immediately.
Depending
on the nature of asynchronous code (I/O, Network call, DNS etc ), Node.js will spawn the “libuv”
thread and using the thread pool it  execute it and as soon as thread processing is done and
 result is ready to process by node runtime,
 event loop checks “is the stack empty ?” If stack is  empty and Queue has some data,
 event loop will take the top most one from it and push it inside of stack for processing.
Task of event loop is to check is there any item present in Queue and if Stack empty then push
it on stack else wait for next tick ( Yes process.nextTick ).
The increment that the event loop moves in is called a ‘tick’, and every time it
‘ticks’ it checks if the call stack is empty.

1. The event loop on every iteration looks if there’s something in the call stack, and executes it:
The event loop is the term given to the process of the waiting for the msg queue to receive a message
 synchronously. The increment that the event loop moves in is called a ‘tick’, and every time it
 ‘ticks’ it checks if the call stack is empty, if so , it adds the top function in the event queue
 to the call stack and executes it.

1. The event loop gives Node the capability to handle highly concurrent requests while still running “single-threaded”.
2 .The event loop on every iteration looks if there’s something in the call stack, and executes it:
3.  when node receives any request it is placed in the call stack,  node js process the request and send it ot client ,
4.  If the request is asynchronous or contains blocking io, event loop delegate it to worker thread and thread pool via event que.
  Worker thread will prepare the response and send it back to event loop which then runs the callback function
  and sends the response to client.
5. The loop gives priority to the call stack, and it first processes everything it finds in the call stack, and once there’s
 nothing in there, it goes to pick up things in the message queue.
 ===

 Phases Overview
 timers:              this phase executes callbacks scheduled by setTimeout() and setInterval().
 pending callbacks:   executes I/O callbacks deferred to the next loop iteration.
 idle, prepare:       only used internally.
 poll:                retrieve new I/O events; execute I/O related callbacks (almost all with the exception of
                      close callbacks, the ones scheduled by timers, and setImmediate()); node will block here when appropriate.
 check:               setImmediate() callbacks are invoked here.
 close callbacks:     some close callbacks, e.g. socket.on('close', ...)

poll phase
 If the poll queue is empty, one of two more things will happen:

 If scripts have been scheduled by setImmediate(), the event loop will end the poll phase and continue
  to the check phase to execute those scheduled scripts.

 If scripts have not been scheduled by setImmediate(), the event loop will wait for callbacks to be
  added to the queue, then execute them immediately.

  Generally, as the code is executed, the event loop will eventually hit the poll phase where it will wait
  for an incoming connection, request, etc. However, if a callback has been scheduled with setImmediate()
  and the poll phase becomes idle, it will end and continue to the check phase rather than waiting for poll events.


timer function----
  What is the purpose of setTimeout function?

  The setTimeout(cb, ms) global function is used to run callback cb after at least ms milliseconds.
  The actual delay depends on external factors like OS timer granularity and system load. A timer
  cannot span more than 24.8 days.
  The time value represents the (minimum) delay after which the message will actually be pushed into the queue.

  This function returns an opaque value that represents the timer which can be used to clear the timer.
  What is the purpose of clearTimeout function?

  The clearTimeout( t ) global function is used to stop a timer that was previously created with
   setTimeout(). Here t is the timer returned by setTimeout() function.
  What is the purpose of setInterval function?
``
  var t = setInterval(() => {
    console.log('---------');
  }, 1000);
  var t1 = setTimeout(() => {
    clearInterval(t);
  }, 4000);
  clearTimeout(t1);


  The setInterval(cb, ms) global function is used to run callback cb repeatedly after at least ms
   milliseconds. The actual delay depends on external factors like OS timer granularity and system
    load. A timer cannot span more than 24.8 days.

  This function returns an opaque value that represents the timer which can be used to clear the
  timer using the function clearInterval(t).

  setImmediate-
  Any function passed as the setImmediate() argument is a callback that’s executed in the next
  iteration of the event loop.
  setImmediate() is designed to execute a script once the current poll phase completes.

  The main advantage to using setImmediate() over setTimeout() is setImmediate() will always be executed
  before any timers if scheduled within an I/O cycle, independently of how many timers are present.

  A setTimeout() callback with a 0ms delay is very similar to setImmediate().+
   The execution order will depend on
  various factors, but they will be both run in the next iteration of the event loop.

  setImmediate(() => {
    console.log('immediate');
  });
  if we run the following script which is not within an I/O cycle (i.e. the main module),
   the order in which the two timers are executed is non-deterministic, as it is bound by
   the performance of the process: print- timeout, immediate

   However, if you move the two calls within an I/O cycle, the immediate callback is always executed first:
   The main advantage to using setImmediate() over setTimeout() is setImmediate() will always be executed
   before any timers if scheduled within an I/O cycle, independently of how many timers are present.
   Browsers have timers. setTimeout() creates a timer, waits until it fires and then adds a task to the queue. It has the signature:

process.nextTick()
  A function passed to process.nextTick() is going to be executed on the current iteration of
  the event loop, after the current operation ends. This means it will always execute before setTimeout and
   setImmediate.

   This is because process.nextTick() is not technically part of the event loop. Instead, the nextTickQueue will be
    processed after the current operation is completed,
    regardless of the current phase of the event loop.
    Here, an  operation is defined as a transition from the underlying C/C++ handler, and handling the JavaScript that needs to be executed.

   all callbacks passed to process.nextTick() will be resolved before the event loop continues.
   This can create some bad situations because it allows you to "starve"/ freeze your I/O by making
    recursive process.nextTick() calls, which prevents the event loop from reaching the poll phase.
    Why use process.nextTick()?
  There are two main reasons:
  Allow users to handle errors, cleanup any then unneeded resources, or perhaps try the request again before the event loop continues.
  At times it's necessary to allow a callback to run after the call stack has unwound but before the event loop continues.
 ====
 "I/O" refers primarily to interaction with the system's disk and network supported by libuv.
 ===
worker threads

Workers (threads) are useful for performing CPU-intensive JavaScript operations.
They will not help much with I/O-intensive work.
The worker_threads module enables the use of threads that execute JavaScript in parallel.:
worker_threads can share memory.

Worker threads have:

One process
Multiple threads
One event loop per thread
One JS Engine Instance per thread
One Node.js Instance per thread

What makes Worker Threads special:

ArrayBuffers-  to transfer memory from one thread to another
MessagePort- used for communicating between different threads. It can be used to transfer structured data, memory regions and
other MessagePorts between different Workers.
MessageChannel represents an asynchronous, two-way communications channel used for communicating between different threads.
SharedArrayBuffer- that will be accessible from either thread. It lets you share memory between threads (limited to binary data).
Atomics available, it lets you do some processes concurrently, more efficiently and allows you to implement conditions variables in JavaScript
WorkerData is used to pass startup data. An arbitrary JavaScript value that contains a clone of the data passed to this thread’s
Worker constructor. The data is cloned as if using postMessage()

What is expected for Workers (hopefully):
1. Passing native handles around (e.g. sockets, http request)
2. Deadlock detection. Deadlock is a situation where a set of processes are blocked because each process is
 holding a resource and waiting for another resource acquired by some other process. Deadlock detention will
 be useful for Worker threads in this case.
3. More isolation, so if one process is affected, it won’t affect others.
====
https://nodesource.com/blog/worker-threads-nodejs/
https://nodejs.org/uk/docs/guides/dont-block-the-event-loop/ ****
worker pool thread pool
1. Node js uses Worker Pool to handle expensive i/o tasks like file I/O
2. Node uses the Event-Driven Architecture: it has an Event Loop for orchestration and a Worker Pool for expensive tasks.
3. Node's Worker Pool is implemented in libuv library, which exposes a general task submission API.
4. Node uses the Worker Pool to handle "expensive" tasks. This includes I/O for which an operating system does not provide
 a non-blocking version, as well as particularly CPU-intensive tasks.
5. the Worker Pool uses a real queue whose entries are tasks to be processed.
   A Worker pops a task from this queue and works on it,
   and when finished the Worker raises an "At least one task is finished" event for the Event Loop.
6.  These are the Node module APIs that make use of this Worker Pool:
 I/O-intensive
 DNS: dns.lookup(), dns.lookupService().
 File System: All file system APIs except fs.FSWatcher() and those that are explicitly synchronous use libuv's threadpool.

 CPU-intensive
 Crypto: crypto.pbkdf2(), crypto.scrypt(), crypto.randomBytes(), crypto.randomFill(), crypto.generateKeyPair().
 Zlib: All zlib APIs except those that are explicitly synchronous use libuv's threadpool.

===
Web Workers
Using Web Workers enables you to offload an expensive operation to a separate thread of execution,
 freeing up the main thread to do other things. The worker includes a separate message queue, event
 loop, and memory space independent from the original thread that instantiated it. Communication
 between the worker and the main thread is done via message passing, which looks very much like the
  traditional, evented code-examples we’ve already seen.
===
Q-2. What Are The Key Features Of Node.Js?

1.Asynchronous event driven IO helps concurrent request handling –
All APIs of Node.js are asynchronous. This feature means that if a Node receives a request for some
Input/Output operation, it will execute that operation in the background and continue with the
processing of other requests. Thus it will not wait for the response from the previous requests.

2.Fast in Code execution – Node.js uses the V8 JavaScript Runtime engine, the one which is used by
Google Chrome. Node has a wrapper over the JavaScript engine which makes the runtime engine much
faster and hence processing of requests within Node.js also become faster.

3.Single Threaded but Highly Scalable –
Node.js uses a single thread model for event looping. The response
from these events may or may not reach the server immediately. However, this does not block other
operations. Thus making Node.js highly scalable. Traditional servers create limited threads to handle
requests while Node.js creates a single thread that provides service to much larger numbers of such
requests.

4.Node.js library uses JavaScript
5. Does not block the main execution thread

When Should We Use Node.Js?
It’s ideal to use Node.js for developing streaming or event-based real-time applications that
require less CPU usage such as.
Chat applications.
Game servers.

Good For A Collaborative Environment.

Advertisement Servers.

Streaming Servers.
To summarize, it’s good to use Node.js, when you need high levels of concurrency but less amount of
dedicated CPU time.

Last but not the least, since Node.js uses JavaScript internally, so it fits best for building
client-side applications that also use JavaScript.
===
When To Not Use Node.Js?
However, we can use Node.js for a variety of applications. But it is a single threaded framework,
so we should not use it for cases where the application requires long processing time.
If the server is doing some calculation, it won’t be able to process any other requests.
 Hence, Node.js is best when processing needs less dedicated CPU time.
===
node modules-
Module in Node.js is a simple or complex functionality organized in single or multiple
JavaScript files which can be reused throughout the Node.js application.

Each module in Node.js has its own context, so it cannot interfere with other modules
or pollute global scope.
Also, each module can be placed in a separate .js file under a separate folder.

Node.js Module Types
Node.js includes three types of modules:

Core Modules
Local Modules
Third Party Modules

core modules-
http	-http module includes classes, methods and events to create Node.js http server.
url	-url module includes methods for URL resolution and parsing.
querystring	-querystring module includes methods to deal with query string.
path	-path module includes methods to deal with file paths.
fs	-fs module includes classes, methods, and events to work with file I/O.
util	-util module includes utility functions useful for programmers.

In order to use Node.js core or NPM modules, you first need to import it
using require() function as shown below.

Node.js Local Module
Local modules are modules created locally in your Node.js application.
These modules include different functionalities of your application in
separate files and folders. You can also package it and distribute it via NPM,
so that Node.js community can use it. For example, if you need to connect to MongoDB
and fetch data then you can create a module for it, which can be reused
in your application.
===
Q-17. What Is EventEmitter In Node.Js?
Answer.
1. Node.js core API is based on asynchronous event-driven architecture in which certain kind of
objects called emitters periodically emit events that cause listener objects to be called.
2. this objects that emit events are members of EventEmitter class.
3. And provides multiple properties like “on” and “emit”. The “on” property is used
    to bind a function to the event and “emit” is used to fire an event.
4. Events module in Node.js allows us to create and handle custom events.
5. When the EventEmitter object emits an event, all of the functions attached to that specific
    event are called synchronously.
     All values returned by the called listeners are ignored and
    will be discarded.
6.The EventEmitter calls all listeners synchronously in the order in which they were registered.

    emitter.addListener(event, listener)
    	Adds a listener to the end of the listeners array for the specified event.
      No checks are made to see if the listener has already been added.

    emitter.on(event, listener)
    Adds a listener to the end of the listeners array for the specified event.
    No checks are made to see if the listener has already been added. It can also be called as an alias of emitter.addListener()

    emitter.emit(event[, arg1][, arg2][, ...])
    Raise the specified events with the supplied arguments.

    emitter.once(event, listener)
    Adds a one time listener for the event. This listener is invoked only the next
    time the event is fired, after which it is removed.

    emitter.removeListener(event, listener)
    Removes a listener from the listener array for the specified event.
    Caution: changes array indices in the listener array behind the listener.

    emitter.removeAllListeners([event])
    Removes all listeners, or those of the specified event.

    emitter.setMaxListeners(n)
    	By default EventEmitters will print a warning if more than 10 listeners are
      added for a particular event.

    emitter.getMaxListeners()
    Returns the current maximum listener value for the emitter which is either
    set by emitter.setMaxListeners(n) or defaults to EventEmitter.defaultMaxListeners.

    emitter.listeners(event)
    Returns a copy of the array of listeners for the specified event.

    emitter.listenerCount(type)
    Returns the number of listeners listening to the type of event.

    const em  = new event.EventEmitter();
    //Subscribe FirstEvent
  em.addListener('FirstEvent', function (data, abc) {
    console.log('First subscriber: ' + data);
      console.log('----: ' + abc);
  });

  //Subscribe SecondEvent
  em.on('SecondEvent', function (data) {
      console.log('First subscriber: ' + data);
  });

  // Raising FirstEvent
  em.emit('FirstEvent', 'This is my first Node.js event emitter example.', 'my abc');

  // Raising SecondEvent
  em.emit('SecondEvent', 'This is my second Node.js event emitter example.');

==
request status code
'500': 'Internal Server Error',
 '501': 'Not Implemented',
 '502': 'Bad Gateway',
 '503': 'Service Unavailable',
 '504': 'Gateway Time-out',
 '505': 'HTTP Version Not Supported',

 401 : unathorized
 403 : forbidden
 404 : not found
 405 : method not allowed

 400 :
 200 : ok
 201 : created
 202 : accepted
 ====
Web Services;

Web services tells us how the communication between two different set of devices or applications held over the World Wide Web (WWW).
This communication system can be categorized into two types, namely Simple Object Access Protocol or SOAP,
and Representational State Transfer or REST.

What Is a REST API?
1. REST is basically an architectural style of the web services that work as a channel of communication between different
computers or systems on the internet. The term REST API is something else.

2. Those application programming interfaces that are backed by the architectural style of REST architectural system
 are called REST APIs.
 3. REST API proides web services, database systems, and computer systems permit requesting
  systems to get robust access
4. it provides web based resources by deploying a predefined set of stateless protocols and standard operations.
5. REST API systems deliver fast performance, reliability, and more progression.

What Is a SOAP API?
1. SOAP is a standard communication protocol system that permits processes using different operating systems like Linux
 and Windows to communicate via HTTP and its XML.
2. SOAP based APIs are designed to create, recover, update and delete
 records like accounts, passwords, leads, and custom objects.
3. These offers over twenty different kinds of calls that make it easy for the API developers to maintain their accounts,
perform accurate searches and much more. These can then be used with all those languages that support web services.
4. SOAP APIs take the advantages of making web based protocols such as HTTP and its XML that are already operating the all
 operating systems thats  why its developers can easily manipulate web services and get responses without caring about
  language and platforms at all.
5/ It includes a WSDL file which has
the required information on what the web service does in
 addition to the location of the web service.

 SOAP uses service interfaces to expose its functionality to client applications.

Differences:
SOAP

REST
SOAP stands for Simple Object Access Protocol
REST stands for Representational State Transfer

SOAP is a protocol. SOAP was designed with a specification.
 It includes a WSDL file which has
 the required information on what the web service does in
  addition to the location of the web service.

-REST is an Architectural style in which a web service
 can only be treated as a RESTful service if it follows the constraints of being
Client Server
Stateless
Cacheable
Layered System
Uniform Interface

SOAP cannot make use of REST since SOAP is a protocol and REST is an architectural pattern.
-REST can make use of SOAP as the underlying protocol for web services,
because in the end it is just an architectural pattern.

SOAP uses service interfaces to expose its functionality to client applications.
 In SOAP, the WSDL file provides the client with the necessary information which
  can be used to understand what services the web service can offer.

- REST use Uniform Service locators to access to the components on the
hardware device. For example, if there is an object which represents
the data of an employee hosted on a URL as http://demo.guru99 , the below
 are some of URI that can exist to access them
http://demo.guru99.com/Employee

SOAP requires more bandwidth for its usage.
Since SOAP Messages contain a lot of information inside of it,
the amount of data transfer using SOAP is generally a lot.
-REST does not need much bandwidth when requests are sent to the server.
 REST messages mostly just consist of JSON messages. Below is an example of
 a JSON message passed to a web server. You can see that the size of the
 message is comparatively smaller to SOAP.
{"city":"Mumbai","state":"Maharastra"}

SOAP can only work with XML format. As seen from SOAP messages,
all data passed is in XML format.
REST permits different data format such as Plain text, HTML, XML, JSON, etc.
But the most preferred format for transferring data is JSON.

========
Blocking vs non Blocking
Blocking

1. Blocking is when the execution of additional JavaScript in the Node.js
process must wait until a non-JavaScript operation completes.
2. This happens because the event loop is unable to continue running JavaScript
while a blocking operation is occurring.
3. A process is labeled blocked if it is not ready for execution but is instead
 waiting for an I/O event to take place. I/O events indicate progress or
 completion in an I/O operation, for example "resource available" or
 "write complete".
 4. Blocking methods execute synchronously and non-blocking methods execute
 asynchronously.

 5. Blocking call waits for the I/O operation to complete before returning.
  Its results are returned synchronously. Nothing else in that process
  takes place during the waiting.

  Non Blocking
  6. In contrast, non-blocking call returns
  immediately without results and uses alternate means to check for completion.
   Other processing can be done while waiting and the results are returned
   asynchronously. Node.js libraries and core api provide non-blocking calls
   that can be used to build performant applications. Such applications make
    use of I/O waiting time to serve other requests.

    Non-blocking functions are used in regards with I/O operations. They immediately respond with whatever data is
     available and keeps on running as per the requests. In case, any answer couldn’t be retrieved then the API returns
     immediately with an error

     ==
     asynchronous vs non Blocking
     synchronous / asynchronous is to describe the relation between two modules.
     blocking / non-blocking is to describe the situation of one module.
=====
how does node prevents blocking code??

By providing callback function. Callback function gets called whenever corresponding event triggered.
===
npx
npx : An npm package runner — helps to execute packages without installing explicitly.

There are times you wanted to try some CLI tools but it’s annoying to have it
installed globally (or) locally just to run it once. npx is a great way for solving this.
Using npx <command> to initiate the execution of a package. If <command> is not already
in your $PATH, npx will install the package from npm registry and invoke it. npx will not maintain
the packages in the globals, So you don't have to worry about polluting your globals.

difference
NPM by itself does not simply run any package. it doesn't run any package in a matter of fact. If you
want to run a package using NPM, you must specify that package in your package.json file.

npx will check whether <command> exists in $PATH, or in the local project binaries, and execute it.
==
yarn
https://engineering.fb.com/web/yarn-a-new-package-manager-for-javascript/
1. makes the install process faster.
2. Fast, reliable, and secure dependency management.
3. Uses Lock files

Yarn resolves these issues around versioning and non-determinism by using lockfiles and an install
algorithm that is deterministic and reliable. These lockfiles lock the installed dependencies to a
specific version, and ensure that every install results in the exact same file structure in node_modules
 across all machines. The written lockfile uses a concise format with ordered keys to ensure that changes
 are minimal and review is simple.

Fast, reliable, and secure dependency management.
Resolution: Yarn starts resolving dependencies by making requests to the registry and recursively looking up each dependency.
Fetching: Next, Yarn looks in a global cache directory to see if the package needed has already been downloaded.
 If it hasn't, Yarn fetches the tarball for the package and places it in the global cache so it can work offline
 and won't need to download dependencies more than once. Dependencies can also be placed in source control as tarballs for full offline installs.
Linking: Finally, Yarn links everything together by copying all the files needed from the global cache into the local node_modules directory.

makes the install process faster.

Fast: Yarn caches every package it downloads so it never needs to again.
It also parallelizes operations to maximize resource utilization so install times are faster than ever.

Reliable: Using a detailed, but concise, lockfile format, and a deterministic algorithm for installs,
Yarn is able to guarantee that an install that worked on one system will work exactly the same way on any other system.

Secure: Yarn uses checksums to verify the integrity of every installed package before its code is executed.

Offline Mode: If you've installed a package before, you can install it again without any internet connection.
Deterministic: The same dependencies will be installed the same exact way across every machine regardless of install order.
Network Performance: Yarn efficiently queues up requests and avoids request waterfalls in order to maximize network utilization.
Multiple Registries: Install any package from either npm or Bower and keep your package workflow the same.
Network Resilience: A single request failing won't cause an install to fail. Requests are retried upon failure.
Flat Mode: Resolve mismatching versions of dependencies to a single version to avoid creating duplicates.
==
error first callback
1. Most asynchronous methods exposed by the Node.js core API follow an idiomatic pattern
referred to as an error-first callback. With this pattern, a callback function is passed
to the method as an argument. When the operation either completes or an error is raised,
the callback function is called with the Error object (if any) passed as the first argument.
 If no error was raised, the first argument will be passed as null.
 ===
 why try catch doesnt work in asynchronous code???
 This will not work because the callback function passed to fs.readFile() is called asynchronously.
  By the time the callback has been called, the surrounding code, including the try…catch block, will
  have already exited. Throwing an error inside the callback can crash the Node.js process in most cases.
   If domains are enabled, or a handler has been registered with process.on('uncaughtException'), such errors can be intercepted.
==
http://book.mixu.net/node/ch7.html
Control flow functions ====
 A control flow function
 is a lightweight, generic piece of code which runs in between several asynchronous
  function calls and which take care of the necessary housekeeping to:

control the order of execution,
collect data,
limit concurrency and
call the next step in the program.

we can use this in
1: Series - an asynchronous for loop
2: Full parallel - an asynchronous, parallel for loop
3: Limited parallel - an asynchronous, parallel, concurrency limited for loop

Nest callbacks to get serial behavior.
Collocate method calls to get parallel behavior.
Use callbacks to untangle nested serial actions.
Use counters to know when groups of parallel actions are finished.
Use libraries like Combo to ease the pain.
====
The Child Processes Module
A child process is the creation of a parent process, which can be defined as the main process
 that creates child or subprocesses to perform certain operations.
 Each process can have many
 child processes but only one parent. A child process inherits most of its parent's attributes.

 Node.js, in its essence, is a single thread process. It does not expose child threads and thread
 management methods to the developer. Technically, Node.js does spawn child threads for certain
 tasks such as asynchronous I/O, but these run behind the scenes and do not execute any application
 JavaScript code, nor block the main event loop.

We can easily spin a child process using Node’s child_process module and those child processes
can easily communicate with each other with a messaging system.

The child_process module enables us to access Operating System functionalities
by running any system command inside a child process.

We can control that child process input stream, and listen to its output stream.
We can also control the arguments to be passed to the underlying OS command,
 and we can do whatever we want with that command’s output.

 There are four different ways to create a child process in Node: spawn(),
 fork(), exec(), and execFile().

 Node.js child_process.exec() method
 The child_process.exec() method runs a command in a console and buffers the output.

 Node.js child_process.spawn() method
The child_process.spawn() method launches a new process with a given command.

This method returns streams (stdout & stderr) and it is generally used when the process returns
 large amount of data.

 Node.js child_process.fork() method
The child_process.fork method is a special case of the spawn() to create Node processes.
This method returns object with a built-in communication channel in addition to having all
the methods in a normal ChildProcess instance.

differnce between spawn and fork

spawn
Spawn is a command designed to run system commands. When you run spawn, you send it a system
 command that will be run on its own process, but does not execute any further code within your
 node process. You can add listeners for the process you have spawned, to allow your code interact
  with the spawned process, but no new V8 instance is created(unless of course your command is
  another Node command, but in this case you should use fork!) and only one copy of your node
   module is active on the processor.

   When a spawn is created - It creates a streaming interface between parent and child process.
streaming interface means - buffering data in binary format

Fork is a special instance of spawn, that runs a fresh instance of the V8 engine.
Meaning, you can essentially create multiple workers, running on the exact same Node code base,
 or perhaps a different module for a specific task. This is most useful for creating a worker pool.
 While node's async event model allows a single core of a machine to be used fairly efficiently,
  it doesn't allow a node process to make use of multi core machines. Easiest way to accomplish
  this is to run multiple copies of the same program, on a single processor.

  When a fork is created - It creates a communication channel between parent and child process
communication channel means - messaging

spawn will be useful when you want to do continuous kind of operation like data read/write in stream

fork will be useful when you want to do messaging

spawn should be used for streaming big data/files/images FROM spawn process TO parent process

fork should be used for doing Json/Xml Data messaging .

===
36. Explain the purpose of ExpressJS package?
Express.js is a framework built on top of Node.js that facilitates the management of the
 flow of data between server and routes in the server-side applications.
  It is a lightweight and flexible framework that provides a wide range of features required
   for the web as well as mobile application development. Express.js is developed on the
   middleware module of Node.js called connect. The connect module further makes use of http
   module to communicate with Node.js. Thus, if you are working with any of the connect based
   middleware modules, then you can easily integrate with Express.js.
===
Why Node.js is single threaded?
Node.js uses a single threaded model in order to support async processing to handleing callbacks.
With async processing,
an application can perform better and is more scalable under web loads. Also can handle concurerent requests
 Thus, Node.js makes use of a
single-threaded model approach rather than typical thread-based implementation.
===
Q-26. What Is Chaining Process In Node.Js?
Answer.
It’s an approach to connect the output of one stream to the input of another stream, thus creating a
chain
of multiple stream operations.
In chaining every method return the object, so that we can chain different calls in single line.

General Chaining:
    Functions may not belong to any single object.
Singleton Chaining:
    Created with object literal, every methods returns object
Instance Chaining:
    Created object with a constructor method and can have many instances

    Advantages of chaining:

    Reduces the headache of creating and maintaining the variables.
    Clean and intuitive code.
    Enforces functional approach.
==
    Q-24. Does Node.Js Support Multi-Core Platforms? And Is It Capable Of Utilizing All The Cores?
Answer.

Yes, Node.js would run on a multi-core system without any issue. But it is by default a
single-threaded application, so it can’t completely utilize the multi-core system.

However, Node.js can facilitate deployment on multi-core systems where it does use the additional
hardware. It packages with a Cluster module which is capable of starting multiple Node.js worker
processes that will share the same port.


Some of important properties of nodejs cluster :

a)isDead : Tells if a worker is dead or alive. It returns true if the worker is ended

b)isConnected : Tells if the worker is connected to it’s master

c)isMaster : tells if current process is master

d)isWorker : Tells if current process is worker

e)worker : Returns current working worker

f)workers : Returns all workers

g)id : Returns unique id for a worker

h)fork : Creates new worker from the master

i)disconnect  : Disconnects all workers

var numCPUs = os.cpus().length;
if (cluster.isMaster) {
  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('online', (worker) => {
    logger.info('worker is online : ', worker.id);

  });
  cluster.on('exit', (worker) => {
    logger.info(`worker ${worker.process.pid} died`);
    cluster.fork();
  });
} else {
  childProcess()
}

What Is <Package.Json>?
A package is:

    a) a folder containing a program described by a package.json file
A package should be installed globally when it provides an executable command that you
run from the shell (CLI), and it’s reused across projects.

    global packages are all put in a single place in your system (exactly where depends on your
    setup), regardless of where you run npm install -g <package-name>
t is a plain JSON (JavaScript Object Notation) text file which contains all metadata information about
 Node.js Project or application.
This file should be present in the root directory of every Node.js Package or Module to describe its
metadata in JSON format.
The file is named as “package” because Node.js platform treats every feature as a separate component.
Node.js calls these as Package or Module.
Who Use It?
NPM (Node Package Manager) uses <package.json> file. It includes details of the Node.js application or
package. This file contains a no. of different directives or elements. These directives guide NPM,
 about how to handle a module or package.

 Q-22. What Is The Local Installation Of Dependencies?
Answer.

By default, NPM installs any dependency in the local mode. It means that the package gets installed
in “node_modules” directory which is present in the same folder, where Node application is placed.
Locally deployed packages are accessible via require(). Following is the syntax to install a Node
 project locally.

 Q-20. What Is NPM In Node.Js?
Answer.

NPM stands for Node Package Manager. It provides following two main functionalities.

It works as an Online repository for node.js packages/modules which are present at <nodejs.org>.
It works as Command line utility to install packages, do version management and dependency
 management of Node.js packages.
  800,000 code packages
  Open-source developers use npm to share software
  Many organizations also use npm to manage private development.

  npm can manage dependencies.

You can publish any directory from your computer as long as the directory has a package.json file.


REPL
A read–eval–print loop (REPL), also termed an interactive toplevel or language shell, is a
 simple, interactive computer programming environment that takes single user inputs
  (i.e., single expressions), evaluates (executes) them, and returns the result to the user; a
  program written in a REPL environment is executed piecewise

  The read function accepts an expression from the user, and parses it into a data structure in memory.
  The eval function takes this internal data structure and evaluates it.
  The print function takes the result yielded by eval, and prints it out to the user.
  The development environment then returns to the read state, creating a loop,
  which terminates when the program is closed.

  As a shell, a REPL environment allows users to access relevant features of an operating system
  in addition to providing access to programming capabilities.
  ===
  Q-19. List And Explain The Important REPL Commands?
  Answer.

  Following is the list of some of the most commonly used REPL commands.

  <.help> – It displays help for all the commands.
  <tab Keys> – It displays the list of all the available commands.
  <Up/Down Keys> – Its use is to determine what command was executed in REPL previously.
  <.save filename> – Save the current REPL session to a file.
  <.load filename> – To Load the specified file in the current REPL session.
  <ctrl + c> – used to Terminate the current command.
  <ctrl + c (twice)> – To Exit from the REPL.
  <ctrl + d> – This command perfoms Exit from the REPL.
  <.break> – It leads Exitting from multiline expression.
  <.clear> – Exit from multiline expression.

  What are Streams?

  Streams are objects that let you read data from a source or write data to
  a destination in continuous fashion. In Node.js, there are four types of streams −
The difference is that streams might not be available all at once, and they don’t have to fit in memory.
This makes streams really powerful when working with large amounts of data, or data that’s
coming from an external source one chunk at a time.
      Readable − Stream which is used for read operation.

      Writable − Stream which is used for write operation.

      Duplex − Stream which can be used for both read and write operation.

      Transform − A type of duplex stream where the output is computed based on input.
      A transform stream is basically a duplex stream that can be used to modify or transform the data as
       it is written and read. An example of that is the zlib.createGzip stream to compress the data using
       gzip. You can think of a transform stream as a function where the input is the writable stream part
        and the output is readable stream part. You might also hear transform streams referred to as
         “through streams.”

The pipe method returns the destination stream, which enabled us to do the chaining above. For streams a (readable), b and c (duplex),
and d (writable), we can:
      =========
      Differentiate between readFile vs createReadStream in Node.js?

Node.js provides two ways to read and execute files which are using readFile and CreateStream.

readFile() is a fully buffered process which returns the response only when the complete file is
 pushed into the buffer and is read. It is a memory intensive process and in case of large files,
  the processing can be very slow.

  Whereas createReadStream is a partially buffered which treats the entire process as an event series.
   The entire file is split into chunks which are then processed and sent back as a response one by one.
    Once done, they are finally removed from the buffer.
    Unlike readFile, createReadStream is really effective for the processing of the large files.
====
Explain the concept of Punycode in Node.js?
In Node.js, Punycode is an encoding syntax that is used for converting Unicode (UTF-8) string of
 characters into a basic ASCII string of characters. It is important as the hostnames can only
 understand the ASCII characters. Thus, Node.js version 0.6.2 onwards, it was bundled up with
 the default Node package. If you want to use it with any previous versions, you can easily do
 that by using the following code:

Syntax:

1
punycode = require('punycode');
===
      Q-7. Is Node.Js Entirely Based On A Single-Thread?

Yes, it’s true that Node.js processes all requests on a single thread. But it’s just a part of the
theory behind Node.js design. In fact, more than the single thread mechanism, it makes use of events
and callbacks to handle a large no. of requests asynchronously.

Moreover, Node.js has an optimized design which utilizes both JavaScript and C++ to guarantee maximum
 performance. JavaScript executes at the server-side by Google Chrome v8 engine. And the C++ libUV
 library takes care of the non-sequential I/O via background workers.

To explain it practically, let’s assume there are 100s of requests lined up in Node.js queue. As per
 design, the main thread of Node.js event loop will receive all of them and forwards to background
  workers for execution. Once the workers finish processing requests, the registered callbacks get
  notified on event loop thread to pass the result back to the user.

  Q-8. How To Get Post Data In Node.Js?

Following is the code snippet to fetch Post Data using Node.js.

app.use(express.bodyParser());
app.post('/', function(request, response){
console.log(request.body.user);
});

Q-9. How To Make Post Request In Node.Js?
Answer.
Following code snippet can be used to make a Post Request in Node.js.
var request = require('request');
request.post(
'http://www.example.com/action',
{ form: { key: 'value' } },
function (error, response, body) {
if (!error && response.statusCode == 200) {
console.log(body)
}
}
);
Q-13. Can You Create HTTP Server In Nodejs, Explain The Code Used For It?
Answer.
Yes, we can create HTTP Server in Node.js. We can use the <http-server> command to do so.

Following is the sample code.

var http = require('http');
var requestListener = function (request, response) {
response.writeHead(200, {'Content-Type': 'text/plain'});
response.end('Welcome Viewers\n');
}
var server = http.createServer(requestListener);
server.listen(8080); // The port where you want to start with.


Q-10. What Is Callback In Node.Js?
Answer.
We may call “callback” as an asynchronous equivalent for a function. Node.js makes heavy use of
callbacks and triggers it at the completion of a given task. All the APIs of Node.js are written
in such a way that they support callbacks.
For example, suppose we have a function to read a file, as soon as it starts reading the file,
 Node.js return the control immediately to the execution environment so that the next instruction
can be executed. Once file read operation is complete, it will call the callback function and pass
the contents of the file as its arguments. Hence, there is no blocking or wait, due to File I/O.
This functionality makes Node.js as highly scalable, using it processes a high number of requests
without waiting for any function to return the expected result.

;
24.3.5 Pros and cons of callbacks
Using callbacks results in a radically different programming style, CPS  Continuation-passing style .
The main advantage of CPS is that its basic mechanisms are easy to understand. But there are also disadvantages:

Error handling becomes more complicated: There are now two ways in which errors are reported – via callbacks and via exceptions.
 You have to be careful to combine both properly.
Less elegant signatures: In synchronous functions, there is a clear separation of concerns between input (parameters)
and output (function result). In asynchronous functions that use callbacks, these concerns are mixed:
 the function result doesn’t matter and some parameters are used for input, others for output.
Composition is more complicated: Because the concern “output” shows up in the parameters, it is more complicated to compose code via combinators.
Callbacks in Node.js style have three disadvantages (compared to those in a functional style):

The if statement for error handling adds verbosity.
Reusing error handlers is harder.
Providing a default error handler is also harder. A default error handler is useful if you make a function call
 and don’t want to write your own handler. It could also be used by a function if a caller doesn’t specify a handler.

promises
then() always returns a Promise, which enables you to chain method calls:

asyncFunc1()
.then(result1 => {
    // Use result1
    return asyncFunction2(); // (A)
})
.then(result2 => { // (B)
    // Use result2
})
.catch(error => {
    // Handle errors of asyncFunc1() and asyncFunc2()
});
How the Promise P returned by then() is settled depends on what its callback does:

If it returns a Promise (as in line A), the settlement of that Promise is forwarded to P.
 That’s why the callback from line B can pick up the settlement of asyncFunction2’s Promise.
If it returns a different value, that value is used to settle P.
If throws an exception then P is rejected with that exception.
Furthermore, note how catch() handles the errors of two asynchronous function calls
(asyncFunction1() and asyncFunction2()). That is, uncaught errors are passed on until there is an error handler.

Promise.all() enables you to be notified once all results are in (a join in Unix process terminology). '
Its input is an Array of Promises, its output a single Promise that is fulfilled with an Array of the results.

The Promise API is about delivering results asynchronously. A Promise object (short: Promise) is a stand-in for
the result, which is delivered via that object.

States:

A Promise is always in one of three mutually exclusive states:
Before the result is ready, the Promise is pending.
If a result is available, the Promise is fulfilled.
If an error happened, the Promise is rejected.
A Promise is settled if “things are done” (if it is either fulfilled or rejected).
A Promise is settled exactly once and then remains unchanged.

Reacting to state changes:

Promise reactions are callbacks that you register with the Promise method then(), to be notified of a fulfillment or a rejection.
A thenable is an object that has a Promise-style then() method. Whenever the API is only interested
in being notified of settlements, it only demands thenables (e.g. the values returned from then() and catch();
 or the values handed to Promise.all() and Promise.race()).

Promises are a pattern that helps with one particular kind of asynchronous programming:
a function (or method) that returns a single result asynchronously. One popular way of receiving such a
 result is via a callback (“callbacks as continuations”):
Promises provide a better way of working with callbacks: Now an asynchronous function returns a Promise,
an object that serves as a placeholder and container for the final result.
 Callbacks registered via the Promise method then() are notified of the result:

Compared to callbacks as continuations, Promises have the following advantages:

No inversion of control: similarly to synchronous code, Promise-based functions return results,
they don’t (directly) continue – and control – execution via callbacks. That is, the caller stays in control.
Chaining is simpler: If the callback of then() returns a Promise (e.g. the result of calling another Promise-based function)
 then then() returns that Promise (how this really works is more complicated and explained later).
  As a consequence, you can chain then() method calls:
Composing asynchronous calls (loops, mapping, etc.): is a little easier, because you have data (Promise objects) you can work with.
Error handling: As we shall see later, error handling is simpler with Promises, because, once again, there isn’t an inversion of control. Furthermore, both exceptions and asynchronous errors are managed the same way.
Cleaner signatures: With callbacks, the parameters of a function are mixed;
 some are input for the function, others are responsible for delivering its output.
 With Promises, function signatures become cleaner; all parameters are input.
Standardized: Prior to Promises, there were several incompatible ways of handling asynchronous results
 (Node.js callbacks, XMLHttpRequest, IndexedDB, etc.).
  With Promises, there is a clearly defined standard: ECMAScript 6. ES6 follows the standard Promises/A+ [1].
  Since ES6, an increasing number of APIs is based on Promises.

25.5.3 Consuming a Promise #
As a consumer of promise, you are notified of a fulfillment or a rejection via reactions – callbacks that you register
with the methods then() and catch():

A thenable is any object that has a method then() that works like Promise.prototype.then().
 Thus, Promises are thenables. Resolving with R (e.g. by returning it from onFulfilled) means that it is inserted
 “after” Q: R’s settlement is forwarded to Q’s onFulfilled and onRejected callbacks. In a way, Q becomes R

diff
Compared to callbacks, Promises have cleaner function (or method) signatures. With callbacks, parameters are used for input and output:
With Promises, all parameters are used for input:

Unified handling of both asynchronous errors and normal exceptions.
Easier composition, because you can reuse synchronous tools such as Array.prototype.map().
Chaining of then() and catch().
Guarding against notifying callbacks more than once. Some development environments also warn about rejections that are never handled.

Q-11. What Is Callback Hell?
Initially, you may praise Callback after learning about it. Callback hell is heavily nested callbacks
which make the code unreadable and difficult to maintain.

Let’s see the following code example.

downloadPhoto('http://coolcats.com/cat.gif', displayPhoto)
function displayPhoto (error, photo) {
if (error) console.error('Download error!', error)
else console.log('Download finished', photo)
}
console.log('Download started')
In this scenario, Node.js first declares the “displayPhoto” function. After that, it calls the “downloadPhoto”
function and pass the “displayPhoto” function as its callback. Finally, the code prints ‘Download started’ on the console.
The “displayPhoto” will be executed only after “downloadPhoto” completes the execution of all its tasks.



Q-12. How To Avoid Callback Hell In Node.Js?
Answer.

Node.js internally uses a single-threaded event loop to process queued events. But this approach may
lead to blocking the entire process if there is a task running longer than expected.

Node.js addresses this problem by incorporating callbacks also known as higher-order functions.
 So whenever a long-running process finishes its execution, it triggers the callback associated.
 With this approach, it can allow the code execution to continue past the long-running task.

However, the above solution looks extremely promising. But sometimes, it could lead to complex and
unreadable code. More the no. of callbacks, longer the chain of returning callbacks would be. Just see
 the below example.

With such an unprecedented complexity, it’s hard to debug the code and can cause you a whole lot of
time. There are four solutions which can address the callback hell problem.

1. Make Your Program Modular.
It proposes to split the logic into smaller modules. And then join them together from the main module
to achieve the desired result.

2. Use Async Mechanism.
It is a widely used Node.js module which provides a sequential flow of execution.

The async module has <async.waterfall> API which passes data from one operation to other using the
 next callback.

Another async API <async.map> allows iterating over a list of items in parallel and calls back with
another list of results.

With the async approach, the caller’s callback gets called only once. The caller here is the main
 method using the async module.

3. Use Promises Mechanism.
Promises give an alternate way to write async code. They either return the result of execution or
 the error/exception. Implementing promises requires the use of <.then()> function which waits for
 the promise object to return. It takes two optional arguments, both functions. Depending on the state
 of the promise only one of them will get called. The first function call proceeds if the promise gets
 fulfilled. However, if the promise gets rejected, then the second function will get called.

4. Use Generators.
Generators are lightweight routines, they make a function wait and resume via the yield keyword.
Generator functions uses a special syntax <function* ()>. They can also suspend and resume asynchronous
operations using constructs such as promises or <thunks> and turn a synchronous code into asynchronous.

====

==
How assert works in Node.js?
In Node.js, assert is used to write tests. It only provides feedback only when any of the running
test cases fails. This module gives you a set of assertion tests which are then used for testing invariants.
It is basically used internally by Node.js but using require(‘assert’) code, it can be used in other applications as well.
===
https://codeburst.io/javascript-unit-testing-using-mocha-and-chai-1d97d9f18e71
Testing in nodejs

The smallest parts of an application are called units, testing of those units to check whether it is fit for use or not is called unit testing.

assert module
The assert module provides a set of assertion functions for verifying invariants.
The module provides a recommended strict mode and a more lenient legacy mode.
deepEqual
Test Assertion
Assertion is an expression which helps system (Mocha in this case) to know code under test failed.
Assert’s job is to just throw an error when things are not correct or right.
Assert tests the expression and it does nothing when expression passes but throws exception in case of failure to tell the test framework about it.
We can just throw an exception to fail the test as well.

assert.strictEqual().
assert.Equal()

testing asynchronous function--
Mocha waits for the done() function to be get called to complete the test.
done();

Chai
Chai is BDD/TDD assertion library.
Can be paired with any javascript testing framework.
Assertion with Chai provides natural language assertions, expressive and readable style.

Assertion interfaces and styles
There are two popular way of assertion in Chai, expect and should
The expect interface provides function for assertion.
The should interface extends each object with a should property for assertion.
should property gets added to the Object.Prototype, so that all object can access it through prototype chain.
You can go through article JavaScript —


var assert = require('assert');
var {expect, should} = require('chai')

describe('Basic Mocha String Test', function () {
 it('should return number of charachters in a string', function () {
        assert.equal("Hello".length, 4);
    });
 it('should return first charachter of the string', function () {
        assert.equal("Hello".charAt(0), 'H');
    });
});


describe('ArrayCheck', () => {
  it('checks the array', () => {
    const test = productsController.checkArray([1, 3, 2], 3);
    assert.equal(test, true);
  })
})
describe('ArrayCheck1', () => {
  it('checks the array1', () => {
    const test = productsController.checkArray([1, 3, 2], 3);
    expect(test).to.be.true;
  })
})

describe('ArrayCheck2', () => {
  it('checks the array2', () => {
    const test = productsController.checkArray([1, 3, 2], 3);
    test.should.equal(true);
  })
})



assert=== helps to determine the status of the test, it determines failure of the test.
describe === is a function which holds the collection of tests. It takes two parameters,
 first one is the meaningful name to functionality under test and second one is the function which contains one
 or multiple tests. We can have nested describe as well.
it === is a function again which is actually a test itself and takes two parameters, first parameter is name to the
 test and second parameter is function which holds the body of the test.

Q-14. What Is The Difference Between Nodejs, AJAX, And JQuery?
Answer.
The one common trait between Node.js, AJAX, and jQuery is that all of them are the advanced
implementation of JavaScript. However, they serve completely different purposes.

Node.Js –
It is a server-side platform for developing client-server applications. For example, if we’ve to
build an online employee management system, then we won’t do it using client-side JS.
But the Node.js can certainly do it as it runs on a server similar to Apache, Django not in a browser.

AJAX (Aka Asynchronous Javascript And XML) –
It is a client-side scripting technique, primarily designed for rendering the contents of a page
 without refreshing it. There are a no. of large companies utilizing AJAX such as Facebook and
 Stack Overflow to display dynamic content.

JQuery –
It is a famous JavaScript module which complements AJAX, DOM traversal, looping and so on.
 This library provides many useful functions to help in JavaScript development. However,
  it’s not mandatory to use it but as it also manages cross-browser compatibility, so can
  help you produce highly maintainable web applications.

Q-15. What Are Globals In Node.Js?
Answer.

There are three keywords in Node.js which constitute as Globals. These are Global, Process, and Buffer.

Global.
The Global keyword represents the global namespace object. It acts as a container for all other
<global> objects. If we type <console.log(global)>, it’ll print out all of them.
An important point to note about the global objects is that not all of them are in the global
 scope, some of them fall in the module scope. So, it’s wise to declare them without using the var
 keyword or add them to Global object.

Variables declared using the var keyword become local to the module whereas those declared without
it get subscribed to the global object.

Process.
The process object is the global object in Node. It can be accessed from anywhere;
it is an instance of  EventEmitter class. And each node application object is an instance of the
Process object.
Each Node.js has a set of built-in functionality, accessible through the global process object.

 The process object provides the standard input/output (stdio) streams
 stdin, stdout and stderr (as in C/C++) as in the following:

 stdin: a readable stream for reading input from the user.
 stdout: a writable stream, either synchrously or asynchronously.
 stderr: a blocking synchronous writable stream intended for error messages.

It primarily gives back the information about the application or the environment.

<process.execPath> – to get the execution path of the Node app.
<process.Version> – to get the Node version currently running.
<process.platform> – to get the server platform.
Some of the other useful Process methods are as follows.
process.pid - It's OS process ID.
process.title: By default a process title is NODE but you can change it.

<process.memoryUsage> – To know the memory used by Node application.
<process.NextTick> – To attach a callback function that will get called during the next loop.
It can cause a delay in executing a function.
The stdout or non-blocking function are: console.log, console.info, util.puts, util.print and Stderr.
====
Buffer.
The Buffer is a class in Node.js to handle binary data.
It represents a fixed-size chunk of memory (can’t be resized) allocated outside of the V8 JavaScript
engine.
 It is similar to a list of integers but
stores as a raw memory outside the V8 heap.

Buffers were introduced to help developers deal with binary data, in an ecosystem that traditionally
only dealt with strings rather than binaries.

 Buffer class is used because pure JavaScript is not compatible with binary data. So, when
  dealing with TCP streams or the file system, it’s necessary to handle octet streams

Buffers are deeply linked with streams. When a stream processor receives data faster than it can
digest, it puts the data in a buffer.

Buffer.from(), Buffer.alloc(memory in kb), Buffer.allocUnsafe()
const buffer = Buffer.from('heyuuu', 'ascii');

We can convert JavaScript string objects into Buffers. But it requires mentioning the encoding
type explicitly.

<ascii> – Specifies 7-bit ASCII data.
<utf8> – Represents multibyte encoded Unicode char set.
<utf16le> – Indicates 2 or 4 bytes, little endian encoded Unicode chars.
<base64> – Used for Base64 string encoding.
<hex> – Encodes each byte as two hexadecimal chars.
Here is the syntax to use the Buffer class.

deprecated
> var buffer = new Buffer(string, [encoding]);
use
> var buffer =buffer.from(string, [encoding]);

The above command will allocate a new buffer holding the string with <utf8> as the default encoding.
 However, if you like to write a <string> to an existing buffer object, then use the following line
 of code.
buffer.alloc(5);
Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled.

buffer.allocUnsafe(5);
 size <integer> The desired length of the new Buffer.
 Allocates a new Buffer of size bytes. If size is larger than buffer.constants.MAX_LENGTH or smaller than 0,
 ERR_INVALID_OPT_VALUE is thrown. A zero-length Buffer is created if size is 0.

> buffer.write(string)
This class also offers other methods like <readInt8> and <writeUInt8> that allows read/write from
 various types of data to the buffer.
====
 4)      What does event-driven programming mean?

 event-driven programming is a programming paradigm in which the flow of the program is
 determined by events such as user actions (mouse clicks, key presses), sensor outputs,
 or messages from other programs or threads.

 In an event-driven application, there is generally a main loop that listens for events,
  and then triggers a callback function when one of those events is detected.

   It is an application architecture technique divided into two sections
   1) Event Selection 2) Event Handling
   ----
   Creating event handlers
The first step in developing an event-driven program is to write a series of subroutines,
or methods, called event-handler routines. These routines handle the events to which the main
 program will respond. For example, a single left-button mouse-click on a command button in a GUI
 program may trigger a routine that will open another window, save data to a database or exit the
 application. Many modern-day programming environments provide the programmer with event templates,
  allowing the programmer to focus on writing the event code.

The second step is to bind event handlers to events so that the correct function is called when
 the event takes place. Graphical editors combine the first two steps: double-click on a button
  and the editor creates an (empty) event handler associated with the user clicking the button
  and opens a text window so you can edit the event handler.

The third step in developing an event-driven program is to write the main loop. This is a function
that checks for the occurrence of events, and then calls the matching event handler to process it.
Most event-driven programming environments already provide this main loop, so it need not be specifically
provided by the application programmer. RPG, an early programming language from IBM, whose 1960s design
concept was similar to event-driven programming discussed above, provided a built-in main I/O loop
(known as the "program cycle") where the calculations responded in accordance to 'indicators' (flags)
that were set earlier in the cycle
===
The two types of API functions in Node.js are

a)      Asynchronous, non-blocking functions

b)      Synchronous, blocking functions
==
Describe the exit codes of Node.js.
In Node.js, exit codes are a set of specific codes which are used for finishing a specific process.
These processes can include the global object as well. Below are some of the exit codes used in Node.js:

Uncaught fatal exception
Unused
Fatal Error
Internal Exception handler Run-time failure
Internal JavaScript Evaluation Failure

===
Explain the reason as to why Express ‘app’ and ‘server’ must be kept separate.
Express ‘app’ and ‘server’ must be kept separate as by doing this, you will be separating the
 API declaration from the network related configuration which benefits in the below listed ways:

It allows testing the API in-process without having to perform the network calls
Faster testing execution
Getting wider coverage metrics of the code
Allows deploying the same API under flexible and different network conditions
Better separation of concerns and cleaner code
API declaration should reside in app.js:

Q5: Why should you separate Express 'app' and 'server'?
Keeping the API declaration separated from the network related configuration (port, protocol, etc)
allows testing the API in-process, without performing network calls, with all the benefits that it
brings to the table: fast testing execution and getting coverage metrics of the code. It also allows
deploying the same API under flexible and different network conditions. Bonus: better separation of
concerns and cleaner code.

var app = express();
app.use(bodyParser.json());
app.use("/api/events", events.API);
app.use("/api/forms", forms);
Server network declaration should reside in /bin/www:

var app = require('../app');
var http = require('http');
//Get port from environment and store in Express
var port = normalizePort(process.env.PORT || '8000');
app.set('port', port);
//Create HTTP server.
var server = http.createServer(app);

======
Is cryptography supported in Node.js?
Yes, Node.js does support cryptography through a module called Crypto.
 This module provides various cryptographic functionalities like cipher, decipher, sign and
 verify functions, a set of wrappers for open SSL’s hash HMAC etc. For example

 ===

diff between exports and module.exports

module is a plain JavaScript object with an exports property. exports is a plain JavaScript variable
 that happens to be set to module.exports. At the end of your file, node.js will basically 'return'
 module.exports to the require function.
 Initially, exports and module.exports point at the same empty object.

so if you attach property a to an exports it will be automatically attach to module.exports because of
the same refernce

so then exports and module.exports are the same object.

but, what if you want to export a function, or a string, or a unicorn?

This is when the difference between exports and module.exports is important.

If you remember nothing else from this article, remember this:

module.exports wins

What this means is that whatever object module.exports is assigned to is the object that is exported from your module.

If you want to export a function from your module and you assign it to exports and not module.exports then this happens:

then your code will return {} object as module.exports = {} not exports = function.

====
export vs export defaults

Named Export: (export)
With named exports, one can have multiple named exports per file. Then import the specific exports they want
surrounded in braces. The name of imported module has to be the same as the name of the exported module.

Default Export: (export default)
One can have only one default export per file. When we import we have to specify a name and import like:

// import
import MyDefaultComponent from "./MyDefaultExport";
// export
const MyComponent = () => {}
export default MyComponent;
The naming of import is completely independent in default export and we can use any name we like.

12)   Can you access DOM in node?

No, you cannot access DOM in node.

)   Using the event loop what are the tasks that should be done asynchronously?

a)      I/O operations

b)      Heavy computation

c)       Anything requiring blocking

What are the two arguments that async.queue takes?

The two arguments that async.queue takes

a)      Task function

b)      Concurrency value

Mention the steps by which you can async in Node.js?

By following steps you can async Node.js

a)      First class functions

b)      Function composition

c)       Callback Counters

d)      Event loops

===
Function composition
Function composition is the process of combining two or more functions to produce a new function.
Composing functions together is like snapping together a series of pipes for our data to flow through.

const add = (a, b) => a + b;
const mult = (a, b) => a * b;
add(2, mult(3, 5))

const users = [
  { name: "Jeff", age: 14 },
    { name: "Jack", age: 18 },
    { name: "Milady", age: 22 },
]
const filter = (cb, arr) => arr.filter(cb);
const map = (cb, arr) => arr.map(cb);

map(u => u.name, filter(u => u.age >= 18, users)); //["Jack", "Milady"]

==
What tools can be used to assure consistent style?
You have plenty of options to do so:

JSLint by Douglas Crockford
JSHint
ESLint
JSCS
===
What's the difference between operational and programmer errors?
Operation errors are not bugs, but problems with the system, like request timeout or hardware failure.

On the other hand programmer errors are actual bugs.
===
Why npm shrinkwrap is useful?
This command locks down the versions of a package's dependencies so that you can control exactly which
versions of each dependency will be used when your package is installed. - npmjs.com

It is useful when you are deploying your Node.js applications - with it you can be sure which versions
 of your dependencies are going to be deployed.
====
 What's a stub? Name a use case.
Stubs are functions/programs that simulate the behaviours of components/modules.
Stubs provide canned answers to function calls made during test cases. Also, you can assert on
with what these stubs were called.

A use-case can be a file read, when you do not want to read an actual file:

var fs = require('fs');

var readFileStub = sinon.stub(fs, 'readFile', function (path, cb) {
  return cb(null, 'filecontent');
});

expect(readFileStub).to.be.called;
readFileStub.restore();
===
What's a test pyramid? How can you implement it when talking about HTTP APIs?
A test pyramid describes that when writings test cases there should be a lot more low-level unit
 tests than high level end-to-end tests.

When talking about HTTP APIs, it may come down to this:

a lot of low-level unit tests for your models
less integration tests, where your test how your models interact with each other
a lot less acceptance tests / end to end test, where you test the actual HTTP endpoints
===
What is the purpose of console object?

console object is used to Used to print information on stdout and stderr.

The Timers module in Node.js contains functions that execute code after a set period of time.
===
Q3: Explain what is Reactor Pattern in Node.js?

Reactor Pattern is an idea of non-blocking I/O operations in Node.js.
 This pattern provides a handler(in case of Node.js, a callback function) that is associated with each I/O operation.
  When an I/O request is generated, it is submitted to a demultiplexer.

This demultiplexer is a notification interface that is used to handle concurrency in non-blocking I/O mode.
it collects every request in form of an event and queues each event in a queue.
Thus, the demultiplexer provides  the Event Queue.

At the same time, there is an Event Loop which iterates over the items in the Event Queue.
Every event has a callback function associated with it, and that callback function is invoked when
the Event Loop iterates.
===
Explain libuv.
Libuv is a multi-platform support library of Node.js which majorly is used for asynchronous I/O.
It was primarily developed for Node.js,  with time it is popularly practiced with other systems
like as Luvit, pyuv, Julia, etc. Libuv is basically an abstraction around libev/ IOCP depending
on the platform, providing users an API based on libev. A few of the important features of libuv are:

Full-featured event loop backed
File system events
Asynchronous file & file system operations
Asynchronous TCP & UDP sockets
Child processes

===
node current - 12.11.1
node lts- 10.16.3

changes in node 10
1. Support for Modern Cryptography
cryptographic support now includes the ChaCha20 cipher and the Poly1305 authenticator.
According to IETF documentation, ChaCha20 is a high-speed cipher (much faster than AES in software only-implementations)
that is not sensitive to timing attacks. The same organization defines Poly1305 as a high-speed message authentication
 code with a straight-forward and easy implementation.

2. Experimental Promisified fs Functions
The experimental fs/promises API gives us a set of alternative asynchronous file system methods that return a Promise
 object instead of using callbacks. We can access this API through require('fs/promises').
Now, we are going to create a function called doTruncate that asynchronously opens the file using open()
 and truncates the content of the file using ftruncate, both methods of the fs/promises library.
ftruncate();
open()
3.
Function.prototype.toString()
This method now returns exact slices of source text which include whitespace and comments.

4.
The catch clause of try statements no longer requires a parameter. Here's an example from the release notes:

5.
Non-standard methods trimLeft() and trimRight() becomes aliases for the newly implemented String.prototype.trimStart()
and String.prototype.trimEnd() to ensure backward compatibility:

6.Performance Improvements
Promises and async functions get a performance boost. The V8 Engineering team has been able to close
the gap between async functions and raw promise chains.
7.
"Node v10 will integrate with NPM v6 before it goes into LTS status in October 2018.
 Get ready to witness up to 17x the speed of last year's npm!"

8.Full Support of N-API
N-API is an API that allows developers to build native Addons.
Node.js Addons are used to provide a performance boost to our codebase when JavaScript performance
 isn't enough. Node.js Addons provide us with an interface between JavaScript running in Node.js and C/C++ libraries.

If an API is a contract between code modules, an ABI is a contract between pieces of binary code as explained
 by Google Engineer Robert Love: an Application Binary Interface (ABI) "defines the mechanisms by which
  functions are invoked, how parameters are passed between caller and callee, how return values are provided to
   callers, how libraries are implemented, and how programs are loaded into memory." A stable ABI for Addons
    will make upgrading codebases that rely on native modules much easier.
----
deprecation

Using non-string values for process.env has been deprecated in documentation.
Passing more than one argument to assert.fail() will emit a runtime deprecation warning
The crypto.createCipher() and crypto.createDecipher() methods have been deprecated in documentation
Previously deprecated internal getters/setters on net.Server has reached end-of-life and have been removed. [3701b02309]
Previously deprecated legacy async_hooks APIs have reached end-of-life and have been removed.
Previously deprecated internal getters/setters on net.Server have reached end-of-life and have been removed.
Using require() to access several of Node.js' own internal dependencies will emit a runtime deprecation.
===
What is LTS releases of Node.js why should you care?
Topic: Node.js
Difficulty: ⭐⭐⭐⭐⭐

An LTS(Long Term Support) version of Node.js receives all the critical bug fixes, security updates
and performance improvements.

LTS versions of Node.js are supported for at least 18 months and are indicated by even version
 numbers (e.g. 4, 6, 8). They're best for production since the LTS release line is focussed on
 stability and security, whereas the Current release line has a shorter lifespan and more frequent
 updates to the code. Changes to LTS versions are limited to bug fixes for stability, security updates,
 possible npm updates, documentation updates and certain performance improvements that can be
  demonstrated to not break existing applications.
===================
Express js

Express is a fast, assertive, essential lightweight and moderate web framework of Node.js.
You can assume express as a layer built on the top of the Node.js that helps manage a server
and routes.
It provides a robust set of features to develop web and mobile applications.

    wxpress js is userd to build Single-page, multi-page, and hybrid mobile and web apps
    Common back-end functions for web applications APIs (application programming interfaces)

    Because Node.js itself wasn’t intended to build websites, the Express framework is able to layer in
    built-in structure and functions needed to actually build a site.

Templating engines: Express comes with two templating engines, Jade and EJS, which facilitate
 the flow of data into a website structure.

 It’s a pretty lightweight framework
that’s great for giving developers extra, built-in web application features and the Express API without
 overriding the already robust, feature-packed Node.js platform.

 Templating engines: Express comes with two templating engines, Jade and EJS, which facilitate the flow
  of data into a website structure.


      It can be used to design single-page, multi-page and hybrid web applications.
      It allows to setup middlewares to respond to HTTP Requests.
      It defines a routing table which is used to perform different actions based on HTTP method and URL.
      It allows to dynamically render HTML Pages based on passing arguments to templates.

 Advantages of Express.js
    Makes Node.js web application development fast and easy.
    Easy to configure and customize.
    Allows you to define routes of your application based on HTTP methods and URLs.
    Includes various middleware modules which you can use to perform additional tasks
     on request and response.
    Easy to integrate with different template engines like Jade, Vash, EJS etc.
    Allows you to define an error handling middleware.
    Easy to serve static files and resources of your application.
    Allows you to create REST API server.
    Easy to connect with databases such as MongoDB, Redis, MySQL

Express.js is based on the Node.js middleware module called connect which in turn uses
++http module. So, any middleware which is based on connect will also work with Express.js.
===
What is Express.js

Let's see some of the core features of Express framework:


    Why use Express
        Ultra fast I/O
        Asynchronous and single threaded
        MVC like structure
        Robust API makes routing easy

        Express 3.x is a light-weight web application framework to help organize your web application
         into an MVC architecture on the server side. You can use a variety of choices for your templating
         language (like EJS, Jade, and Dust.js).

        You can then use a database like MongoDB with Mongoose (for modeling) to provide a backend for your
        Node.js application.
        Express.js basically helps you manage everything, from routes, to handling requests and views.

        What is the purpose of it with Node.js?

That you don't have to repeat same code over and over again.
Node.js is a low-level I/O mechanism which has an HTTP module. If you just use an HTTP module,
a lot of work like parsing the payload, cookies, storing sessions (in memory or in Redis), selecting
 the right route pattern based on regular expressions will have to be re-implemented.
 With Express.js, it is just there for you to use.

 Easy integration of third-party services and middleware
 Disadvantages-
 Event-driven nature (callbacks)
 Philosophy of plugins known as middleware

Express.js is built on this philosophy, that is why it is important to understand its main concepts.
 In short, middleware is a subset of chained functions that run between the client request and the server answer.

Code organization

Note that the code organization in Express.js is represented by patterns that make your code
easier to maintain. Here are some useful tips for simplifying the development process
===
What function are arguments available to Express JS route handlers?
Answer:
The arguments which are available to an Express JS route handler-function are-

• Req – the request object
• Res – the response object
• Next (optional) – a function that is employed to pass management to 1 of the following
 route handlers.

The third argument is optional and should be omitted, however, in some cases, it’s helpful wherever
there’s a series of handlers and management will be passed to 1 of the following route handlers
skipping this one.
===
6. How to allow CORS in Express JS? Explain with an example?

Cross-Origin Resource Sharing (CORS) is a mechanism that uses additional HTTP headers to tell a
browser to let a web application running at one origin (domain) have permission to access selected
resources from a server at a different origin.

In order to permit CORS in Express.js, add the subsequent code in server.js:
For Example –
app.all(‘*’, function(req, res, next) {
res.set(‘Access-Control-Allow-Origin’, ‘*’);
res.set(‘Access-Control-Allow-Methods’, ‘GET, POST, DELETE, PUT’);
res.set(‘Access-Control-Allow-Headers’, ‘X-Requested-With, Content-Type’);
if (‘OPTIONS’ == req.method) return res.send(200);
next();
});


set headers
res.set({
  'Content-Type': 'text/plain',
  'Content-Length': '123',
  'ETag': '12345'
})
app.use((req, res, next) => {
    res.append('Access-Control-Allow-Origin', ['*']);
    res.append('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE');
    res.append('Access-Control-Allow-Headers', 'Content-Type');
    next();
});

====

uestion 13. What Is The Parameter “next” Used For In Express?

Answer :
Next simply allows the next route handler in line to handle the request.

app.get('/userdetails/:id?', function(req, res, next){
 });

req and res which represent the request and response objects

nextIt passes control to the next matching route.

In this case you need both the middleware functions to be invoked.
So, the only way you reach the second middleware function is by calling next();
====
Authentication and Authorization
Authentication means confirming your own identity, whereas authorization means
being allowed access to the system. In even more simpler terms
 authentication is the process of verifying oneself, while authorization is
 the process of verifying what you have access to.

 Authentication
 Authentication is about validating your credentials such as Username/User ID
 and password to verify your identity. The system then checks whether you are what
  you say you are using your credentials. Whether in public or private networks,
  the system authenticates the user identity through login passwords. Usually
  authentication is done by a username and password, although there are other
  various ways to be authenticated.

  Authorization
  Authorization occurs after your identity is successfully authenticated by the system,
  which therefore gives you full access to resources such as information, files, databases,
  funds, etc. However authorization verifies your rights to grant you access to resources only
  after determining your ability to access the system and up to what extent.
   In other words, authorization
   is the process to determine whether the authenticated user has access to the particular resources.
    A good example of this is, once verifying and confirming employee ID and passwords through authentication,
     the next step would be determining which employee has access to which floor and that is done through authorization.
  Access to a system is protected by authentication and authorization, and they are frequently used in conjunction
  with each other. Although both have different concepts behind then, they are critical to the web service
   infrastructure, especially when it comes to being granted access to a system. Understanding each
   term is very important and a key aspect of security.

  Single- Factor Authentication: This is the simplest form of authentication method which
  requires a password to grant user access to a particular system such as a website or a network.
  The person can request access to the system using only one of the credentials to verify one’s
   identity. For example, only requiring a password against a username would be a way to verify a
   login credential using single- factor authentication.

Two- Factor Authentication: This authentication requires a two- step verification process which
not only requires a username and password, but also a piece of information only the user knows.
Using a username and password along with a confidential information makes it that much harder
for hackers to steal valuable and personal data.

Multi- Factor Authentication: This is the most advanced method of authentication which requires
 two or more levels of security from independent categories of authentication to grant user
 access to the system. This form of authentication utilizes factors that are independent of
 each other in order to eliminate any data exposure. It is common for financial organizations,
 banks, and law enforcement agencies to use multiple- factor authentication.
====
 jsonwebtoken
 let token = jwt.sign({
   name:#name
 }, #secret, {
   expiresIn: 120 // expires in 24 hours
 });

 jwt.verify(token, config.secrets.session, cb(err, res) {

 });
===
Question 17. How To Redirect 404 Errors To A Page In Expressjs?
Answer :

In server.js add the following code to redirect 404 errors back to a page in our ExpressJS App:

/* Define fallback route */
app.use(function(req, res, next) {
    res.status(404).json({errorCode: 404, errorMsg: "route not found"});
});

===
Q.3) What is Scaffolding in Express JS?
Scaffolding is creating the skeleton structure of application

There are 2 way to do this:

Express application generator
Yeoman
====
Q.6) What is routing and how routing works in Express.js?
Routing refers to determining how an application responds to a client request to a particular endpoint, which is a URI (or path) and
a specific HTTP request method (GET, POST, and so on).
Each route can have one or more handler functions, which are executed when the route is matched.

Route Syntax:
codesource
app.METHOD(PATH, HANDLER)
Where:

app is an instance of express.
METHOD is an HTTP request method, in lowercase.
PATH is a path on the server.⭐
HANDLER is the function executed when the route is matched.
#Example:

codesource
app.get('/', function (req, res) {
  res.send('Express Js Interview Questions')
})

Dynamic routing and how it works in Express.js?
When someone pass parameters in URL i.e. Parametrized URL,
this routing phenomenon is called dynamic
 routing.

codesource
var express = require('express'),
app = express();


const Router = express.Router({mergeParams : true});

app.get('/article/:id', function(req , res){
  res.render('article' + req.params.id);
})
In above example: id is a parameters, which can be different for different calls.
===
Q.7) What is middleware in Express Js?

Middleware functions are functions that have access to the request object (req),
the response object (res), and the next middleware function in the application’s
request-response cycle. The next middleware function is commonly denoted by a variable
 named next.
 The next function is a function in the Express router which, when invoked,
 executes the middleware succeeding the current middleware.
 As name suggests it comes in middle of something and that is request and response cycle
Middleware has access to request and response object
Middleware has access to next function of request-response life cycle.

Middleware functions can perform the following tasks:
Execute any code.
Make changes to the request and the response objects.
End the request-response cycle.
Call the next middleware in the stack.

If the current middleware function does not end the request-response cycle,
it must call next() to pass
 control to the next middleware function. Otherwise, the request will be left hanging.

An Express application can use the following types of middleware:
Application-level middleware
Router-level middleware
Error-handling middleware
Built-in middleware
Third-party middleware
1. Application-level middleware
This kind of middleware method is bind to the app Object using app.use() method.

codesource
//This middleware will execute for each route.
app.use(function (req, res, next) {
  console.log('Current Time:', Date.now())
  next()
})
2. Router-level middleware:
Router-level middleware works in the same way as application-level middleware, except it is bound to
an instance of express.Router()

3. Built-in middleware:
Starting with version 4.x, Express no longer depends on Connect.

Express has the following built-in middleware functions:

express.static serves static assets such as HTML files, images, and so on.
express.json parses incoming requests with JSON payloads. NOTE: Available with Express 4.16.0+
express.urlencoded parses incoming requests with URL-encoded payloads.
NOTE: Available with Express 4.16.0+

4. Third-party middleware:
There are a number of third party middleware, such as body-parser cookie-parser, mongoose and so on.

To handle HTTP POST request in Express.js version 4 and above, you need to install middleware
module called body-parser, body-parser extract the entire body portion of an incoming request stream
 and exposes it on req.body, The middleware was a part of Express.js earlier but now you have to install it separately.

These can be installed by using command:
codesource
>> npm install MODULE_NAME
And they can be loaded using requires and used later.

#Example:
codesource
var bodyParser = require('body-parser');
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: false }))
====
bodyParser
parsing - analyse (a string or text) into logical syntactic components.

Node.js body parsing middleware.

Parse incoming request bodies in a middleware before your handlers, available under the req.body property.
====
app.set(name, value)
Assigns setting name to value. You may store any value that you want, but certain names can be used
to configure the behavior of the server. These special names are listed in the app settings table.

Calling app.set('foo', true) for a Boolean property is the same as calling app.enable('foo'). Similarly, calling app.set('foo', false) for a Boolean property is the same as calling app.disable('foo').
===
req.body
Contains key-value pairs of data submitted in the request body. By default, it is undefined,
and is populated when you use body-parsing middleware such as express.json() or express.urlencoded().
---
req.params
This property is an object containing properties mapped to the named route “parameters”.
For example, if you have the route /user/:name, then the “name” property is available as
req.params.name. This object defaults to {}.
===
req.query
This property is an object containing a property for each query string parameter
in the route. If there is no query string, it is the empty object, {}.
// GET /search?q=tobi+ferret
console.dir(req.query.q)

===
response object methods

res.append(field [, value])
res.append() is supported by Express v4.11.0+

Appends the specified value to the HTTP response header field. If the header is not already set, it creates the header
with the specified value. The value parameter can be a string or an array.

Note: calling res.set() after res.append() will reset the previous

---
res.download(path [, filename] [, options] [, fn])
The optional options argument is supported by Express v4.16.0 onwards.

Transfers the file at path as an “attachment”. Typically, browsers will prompt the user for download.
By default, the Content-Disposition header “filename=” parameter is path (this typically appears
in the browser dialog). Override this default with the filename parameter.
--
res.end([data] [, encoding])
Ends the response process. This method actually comes from Node core, specifically the response.end() method of http.ServerResponse.
--
res.format(object)
Performs content-negotiation on the Accept HTTP header on the request object, when present.
 It uses req.accepts() to select a handler for the request, based on the acceptable types ordered
  by their quality values. If the header is not specified, the first callback is invoked.
  When no match is found, the server responds with 406 “Not Acceptable”, or invokes the default callback.

The Content-Type response header is set when a callback is selected. However, you may alter this within the
callback using methods such as res.set() or res.type().

res.format({
  'text/plain': function () {
    res.send('hey')
  },
---
res.get(field)
Returns the HTTP response header specified by field. The match is case-insensitive.
---
res.json([body])
Sends a JSON response. This method sends a response (with the correct content-type) that is the parameter converted
to a JSON string using JSON.stringify().

The parameter can be any JSON type, including object, array, string, Boolean, number, or null, and you
can also use it to convert other values to JSON.
---
res.jsonp([body])
Sends a JSON response with JSONP support. This method is identical to res.json(), except that it opts-in to JSONP callback support.
=--
res.render(view [, locals] [, callback])
Renders a view and sends the rendered HTML string to the client. Optional parameters:
---
res.send([body])
Sends the HTTP response.

The body parameter can be a Buffer object, a String, an object, or an Array. For example:
--
res.sendStatus(statusCode)
Sets the response HTTP status code to statusCode and send its string representation as the response body.
res.sendStatus(200) // equivalent to res.status(200).send('OK')
res.sendStatus(403) // equivalent to res.status(403).send('Forbidden')
---
res.set(field [, value])
Sets the response’s HTTP header field to value. To set multiple fields at once, pass an object as the parameter.
--
res.status(code)
Sets the HTTP status for the response. It is a chainable alias of Node’s response.statusCode.

res.status(403).end()
---
Http methods
idempotent - does produce the same result when hit multiple times
Get
Simply put, the GET method is used to retreive data from a server at the specified resource.
Since a GET request is only requesting data and not modifying any resources, it's considered a safe and idempotent method.

Post
POST
In web services, POST requests are used to send data to the API sever to create or udpate a resource.
 The data sent to the server is stored in the request body of the HTTP request.
It's worth noting that a POST request is non-idempotent. It mutates data on the backend server (by creating or updating a resource),

Put
PUT
Simlar to POST, PUT requests are used to send data to the API to create or update a resource. The difference is that PUT requests
are idempotent. That is, calling the same PUT request multiple times will always produce the same result. In contrast, calling a
 POST request repeatedly make have side effects of creating the same resource multiple times.

Patch
The difference with PATCH is that you only apply partial modifications to the resource.

The difference between PATCH and PUT, is that a PATCH request is non-idempotent (like a POST request).

Delete

The DELETE method is exactly as it sounds: delete the resource at the specified URL.


HEad
HEAD
The HEAD method is almost identical to GET, except without the response body.
 In other words, if GET /users returns a list of users,
 then HEAD /users will make the same request but won't get back the list of users.
 HEAD requests are useful for checking what a GET request will return before actually
  making a GET request -- like before downloading a large file or response body

Options
PTIONS request should return data describing what other methods and operations the server supports at the given URL.

OPTIONS requests are more loosely defined and used than the others, making them a good candidate to test for fatal API errors.
---
not following the Methods
HTTP GET method is specified as idempotent, a GET request, by specification, can be resubmitted
with the assumption that it will not change anything on the server.
This is not the case for a HTTP POST which by specification can change the status of the application running on the server.

as a last example, web browsers warn users when they try to refresh a page that was reached by a
HTTP POST request warning that some data might be resubmitted. You do not get that layer of protection
built-in browsers if the page is reached by a HTTP GET request.
====
26. Explain the concept of URL module.
The URL module of Node.js provides various utilities for URL resolution and parsing.
 It is a built-in module that helps in splitting up the web address into a readable format:

1
var url = require('url');
For example:
var url = require('url');
var adrs = '<a href="http://localhost:8082/default.htm?year=2019&month=april">http://localhost:8082/default.htm?year=2019&month=april</a>';
var q = url.parse(adr, true);
console.log(q.host); //returns 'localhost:8082'
console.log(q.pathname); //returns '/default.htm'
console.log(q.search); //returns '?year=2019 and month=april'
var qdata = q.query; //returns an object: { year: 2019, month: 'april' }
console.log(qdata.month); //returns 'april'
====
NODE_ENV==

NODE_ENV is an environment variable made popular by the express webserver framework. When a node
 application is run, it can check the value of the environment variable and do different things
based on the value. NODE_ENV specifically is used (by convention) to state whether a particular
environment is a production or a development environment. A common use-case is running additional
debugging or logging code if running in a development environment.

Accessing NODE_ENV
You can use the following code to access the environment variable yourself so that you can perform your own checks and logic:

var environment = process.env.NODE_ENV

Or alternatively using express' app.get('env') (note: this defaults to "development")

Be aware that if you haven't explicitly set NODE_ENV for your environment, it will be undefined.

Setting NODE_ENV
How to actually set the environment variable varies from operating system to operating system, and also depend on your user setup.

If you want to set the environment variable as a one-off, you can do so from the command line:

linux & mac: export NODE_ENV=production
windows: $env:NODE_ENV = 'production'

GARBAGE COLLECTION-

The JavaScript Engine’s Garbage collector basically looks out for unreachable objects which are
removed from the memory. There are two garbage collection algorithms that I would like to explain
 which are as follows:
Reference-counting garbage collection
Mark-and-sweep algorithm

Reference-counting garbage collection
This is a naïve garbage collection algorithm. This algorithm looks out for those objects which
have no references left. An object becomes eligible for garbage collection if it has no references
attached to it.

Mark-and-Sweep Algorithm
This algorithm looks out for objects which are unreachable from the root which is the JavaScript’s
 global object. This algorithm overcomes the limitations of Reference-counting algorithm.
 This algorithm starts from the root and traverses down to all other objects while marking them .
 It further traverses through the traversed objects and marks them. This process continues till the
  algorithm has no child nodes or any path left to traverse while marking all the nodes that have
  been traversed. Now the garbage collector ignores all the reachable objects as they were marked
  while traversing. So all the objects that were not marked were clearly unreachable to the root
  which makes them eligible for garbage collection and later the memory is freed by removing those
   objects.

   Dependency vs Dev Dependency & peerDependaancy?

   The difference between these two, is that devDependencies are modules which are only required
   during development,
    while dependencies are modules which are also required at runtime.
     npm install --save-dev, instead of just an npm install --save.
     Some good examples of when to install devDependencies would be Nodemon, Babel, ESLint,Gulp, and
     testing frameworks like Chai, Mocha, Enzyme,

     peerdependancies -
     in case u have dependancies which ur app required is of other version and the
     same dependancy is required or used by another module but of diffrent versions
     then we define peerDependancy.
===
orm-
1. orm  is a programming technique for converting data between incompatible type systems using object-oriented programming languages.
2. This creates, in effect, a "virtual object database" that can be used, accessed and modified from within the programming language.
3. ORM hides and encapsulates change in the data source itself, so that when data sources or their APIs change, only ORM needs to
 change to keep up—not the applications that use ORM to insulate themselves from this kind of effort.

node orm-
Sequelize
NOde-Orm2
bookshelf
objection.js
caminte.js
sequelize support PostgreSQL, MySQL, MariaDB, SQLite and MSSQL

why to use/advantage
 we dont need to do database language specific query to perform db operation
 it hides the database asbstraction so we can sweetch betwwen the orm supproted db
 Depending on the ORM you get a lot of advanced features out of the box, such as
  support for transactions, connection pooling, migrations, seeds, streams, and all sorts of other goodies.

ORM solutions are useful to facilitate data-driven API development.
Users have concrete needs which drive the data model of an application.
In legacy development, this data architecture is typically implemented and version controlled
 using database scripts such as SQL scripts.
  A separate library is then used for the server application to execute CRUD actions on the database.

ORMs work as a high-level API to execute CRUD, and these days quality ORMs also allow us to
initialize the data through code. Complex data manipulation, cleaning and so on, is often easier
in code. While dedicated Extract, Transform and Load (ETL) tools exist, the same ETL tasks can
be easily implemented in ORM.
===
   migrations
      Using migrations allows you to easily and safely update your tables and database.
      Just like you use Git / SVN
      to manage changes in your source code, you can use migrations to keep track of changes
      to the database
      With migrations you can transfer your existing database into another state and vice versa:
      Those state
      transitions are saved in migration files, which describe how to get to the new state
      and how to revert the changes in order to get back to the old state.

      Model-
      Sequelize will only use Model files, it's the table representation. On the other hand,
      the migration file
      is a change in that model or more specifically that table, used by CLI.
      Treat migrations like a commit or a
      log for some change in database

      Suppose we want to insert some data into a few tables by default.
       If we follow up on previous example we can consider
       creating a demo user for User table.

   Seeders
   To manage all data migrations you can use seeders. Seed files are some change in data that
    can be used to
    populate database table with sample data or test data.
===
how to connect to the database

sequelize
const sequelize = new Sequelize('database', 'username', 'password', {
  host: 'localhost',
  dialect: /* one of 'mysql' | 'mariadb' | 'postgres' | 'mssql' */
});
----
postgres
var pg = require('pg');
var client = new pg.Client(conString);
client.connect();
----
mysql
let mysql = require('mysql');

let connection = mysql.createConnection({
    host: 'localhost',
    user: 'root',
    password: '',
    database: 'todoapp'
});
connection.connect(function(err) {
  if (err) {
    return console.error('error: ' + err.message);
  }

  console.log('Connected to the MySQL server.');
});


==
   View vs materialized view
   Definition of View
   View is a virtual table, created using Create View command. This virtual table contains the data
   retrieved from a query expression,
    in Create View command. View can be created from one or more than one base tables or views.
    A view can be queried like you query
    the original base tables.

   It is not that the View is precomputed and stored on the disk instead, a View is computed each
    time it is used or accessed.
   Whenever a view is used the query expression in Create View command is executed at that particular
    moment. Hence, you always
   get the updated data in a View.

   If you update any content in View, it is reflected in the original table, and if any changes had
   been done to the original
    base table, it would reflect in its View. But this makes the performance of a View slower.
    For example, a view is created
    from the join of two or more tables. In that case, you have to pay time to resolve Joins each
    time a View is used.

   But it has some advantages like it do not require storage space. You can create a customized view of
    a complex database.
   You can restrict the user from accessing sensitive information in a database. Reduces the complexity
   of queries by getting
    data from several tables into a single customized View.
===
    Error Handling
    Catching uncaught exceptions
If an uncaught exception gets thrown during the execution of your program, your program will crash.
To solve this, you listen for the uncaughtException event on the process object:

process.on('uncaughtException', (err) => {
    console.error('There was an uncaught error', err)
    process.exit(1) //mandatory (as per the Node docs)
})

using error catching middleware
app.use((err, req, res, next) => {
if(err) {
return throw err;
}
next();
})

Error handling with async/await

async function someFunction() {
  try {
    await someOtherFunction()
  }
  catch (err) {
    console.error(err.message)
  }
}

try {
  //lines of code
} catch (e) {

}
===
Anatomy of an error object
The first argument for a native error object is its description. The description is the human-readable
 string of your error object. It’s what pops up in your console when something goes awry.

Second error objects also have a name property, which is the computer-readable part of the object.
 When you use the native error object, the name property defaults to the generic “Error.” , but you
  can create your own. The best way to do this is by extending the native error object like so:

  throw new Error('database failed to connect');

  When JavaScript finds a throw keyword, the first thing it does is stop dead in its tracks,
  which prevents any more functions from running. By stopping like this, it mitigates the risk of any
  further errors occurring and helps us not to get the state of our program all twisted.

With the program halted, JavaScript will begin to look back up the daisy chain of functions that were
called in order to reach a catch statement. This daisy chain is called the call stack (don’t worry—we’ll
 get to the call stack soon). The nearest catch that JavaScript finds is where the thrown exception will
 emerge. If no try/catch is found, the exception throws, and the Node.js process will exit, causing the server to restart.
===
Error vs Throw New Error()

The Error constructor creates an error object. Instances of Error objects are thrown when runtime errors occur.
The Error object can also be used as a base object for user-defined exceptions. See below for standard built-in error types.

When Error is used like a function -- without new, it will return an Error object. Therefore, a mere call to
Error will produce the same output that constructing an Error object via the new keyword would.

named and ananomous function = >
// Anonymous function
const one = () => {};

// Anonymous functions
const two = function () {};

// Explicitly named function
const three = function explicitFunction() {};


To catch or not to catch promises?
At this point, you might be wondering whether adding a catch to your promises is optional. Yes it’s optional,
but you should always provide a catch handler.

Why? Because there are many ways your asynchronous calls can fail. Our code might timeout, it could have network issues,
or there might be a hardware failure. For all of these reasons, you should always instruct
your program what to do in the case of a promise failure.

Remember the golden rule: always handle promise rejections.

Try/catch is by default synchronous. That means that if an asynchronous function throws an error in a synchronous try/catch block, no error throws.


v8 engine-
In order to obtain speed, V8 translates JavaScript code into more efficient machine code instead of using an interpreter.
It compiles JavaScript code into machine code at execution by implementing a JIT (Just-In-Time) compiler like a lot of
modern JavaScript engines such as SpiderMonkey or Rhino (Mozilla) are doing.
 The main difference with V8 is that it doesn’t produce bytecode or any intermediate code.
Instead of using a dictionary-like data structure for storing object properties and doing a dynamic lookup
to resolve the property location (like most JavaScript engines do), V8 creates hidden classes, at runtime,
in order to have an internal representation of the type system and to improve the property access time.
V8 has two compilers!

A “Full” Compiler that can generate good code for any JavaScript: good but not great JIT code.
The goal of this compiler is to generate code quickly. To achieve its goal, it doesn’t do any type analysis
and doesn’t know anything about types. Instead, it uses an Inline Caches or “IC” strategy to refine knowledge
about types while the program runs. IC is very efficient and brings about 20 times speed improvment.

An Optimizing Compiler that produces great code for most of the JavaScript language. It comes later and
re-compiles hot functions. The optimizing compiler takes types from the Inline Cache and make decisions about
how to optimize the code better. However, some language features are not supported yet like try/catch blocks for instance.
 (The workaround for try/catch blocks is to write the “non stable” code in a function and call the function in the try block)

Code optimization: V8 also supports de-optimization: the optimizing compiler makes optimistic assumptions from the Inline
Cache about the different types, de-optimization comes if these assumptions are invalid. For example, if a hidden
class generated was not the one expected, V8 throws away the optimized code and comes back to the Full Compiler
to get types again from the Inline Cache. This process is slow and should be avoided by trying to not change functions
after they are optimized.
====
what us hidden classes & whats the advantage.

https://richardartoul.github.io/jekyll/update/2015/04/26/hidden-classes.html

Javascript is dynamically type language. while accessing the objects and its properties the v8
engine doesnt follow the disctionary approach, i,e looking for the objects and prperties in the storage
beacuse object properties can be created and destroyed at run time.

for each object creation and for each property it creates the hidden class and set the offset
of each property.
if any property is added to the object the new hidden class is created with the incremental offset and
old object hidden class is updated with the transition path to the new.

v8 engine makes use of inline cashing while compiling the code.
v8 eng stores the information about the type of object that is passed
in the recent method calls and use that information to make assumption for the same
type of objct that will be passed in the future.
if v8 makes good assumption about the object it makes use of stored information from
the previous lookup hidden classes.

Whenever a method is called on a specific object, the V8 engine has to perform a lookup
 to that objects hidden class to determine the offset for accessing a specific property.
  After two successful calls of the same method to the same hidden class, V8 omits the hidden
  class lookup and simply adds the offset of the property to the object pointer itself.
   For all future calls of that method, the V8 engine assumes that the hidden class hasn’t
    changed, and jumps directly into the memory address for a specific property using the
     offsets stored from previous lookups; this greatly increases execution speed.

 Event Loop executes the JavaScript callbacks registered for events, and is also responsible for
 fulfilling non-blocking asynchronous requests like network I/O.
=======
microservicess -
Microservices solve these challenges of monolithic systems by being as modular as possible.
In the simplest form, they help build an application as a suite of small services, each
running in its own process and are independently deployable. These services may be written
in different programming languages and may use different data storage techniques. While this
results in the development of systems that are scalable and flexible, it needs a dynamic
makeover
==
7.How to enable debugging in express app?

Answer:
In different operative Systems, we’ve got following commands:

On UNIX operating system the command would be as follows:

$ DEBUG=express:* node index.js

On Windows the command would be:

set DEBUG=express:* & node index.js
From Webstrome IDE


====
Question 8. How To Output Pretty Html In Express.js?

Answer :

app.set('view options', { pretty: true });

===
How To Get The Full Url In Express?

Answer :

var port = req.app.settings.port || cfg.port;

res.locals.requested_url = req.protocol + '://' + req.host  + ( port == 80 || port == 443 ? '' : ':'+port ) + req.path;

===

Question 10. How To Remove Debugging From An Express App?

Answer :

var io = require('socket.io').listen(app, { log: false });
io.set('log level', 1);

====
Question 12. How To Download A File?

Answer :

app.get('/download', function(req, res){
  var file = __dirname + '/download-folder/file.txt';
  res.download(file);
});

====
How can you make sure your dependencies are safe?
When writing Node.js applications, ending up with hundreds or even thousands of dependencies can easily happen.
For example, if you depend on Express, you depend on 27 other modules directly, and of course on those dependencies'
as well, so manually checking all of them is not an option!

The only option is to automate the update / security audit of your dependencies. For that there are free and paid options:

npm outdated
Trace by RisingStack
NSP
GreenKeeper
Snyk
====
cookies

Set Cookie?
cookies.set( name, [ value ], [ options ] )
res.cookie('cookieName', 'cookieValue')
Read Cookie?

req.cookies.cookieName = " value"
cookies.get( name, [ options ] )

maxAge: a number representing the milliseconds from Date.now() for expiry
expires: a Date object indicating the cookie's expiration date (expires at the end of session by default).
path: a string indicating the path of the cookie (/ by default).
domain: a string indicating the domain of the cookie (no default).
secure: a boolean indicating whether the cookie is only to be sent over HTTPS (false by default for HTTP, true by default for HTTPS).
    Read more about this option below.
httpOnly: a boolean indicating whether the cookie is only to be sent over HTTP(S), and not made available to client JavaScript (true by default).
sameSite: a boolean or string indicating whether the cookie is a "same site" cookie (false by default). This can be set to 'strict', 'lax', or true (which maps to 'strict').
signed: a boolean indicating whether the cookie is to be signed (false by default). If this is true, another cookie of the same name with the .sig suffix appended will also be sent, with a 27-byte url-safe base64 SHA1 value representing the hash of cookie-name=cookie-value against the first Keygrip key. This signature key is used to detect tampering the next time a cookie is received.
overwrite: a boolean indicating whether to overwrite previously set cookies of the same name (false by default). If this is true, all cookies set during the same request with the same name (regardless of path or domain) are filtered out of the Set-Cookie header when setting this cookie.
==
