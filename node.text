Q-1. What Is Node.Js?

1. Node.js is a JavaScript runtime or platform which is built on Google Chrome’s JavaScript v8 engine.
This runtime allows executing the JavaScript code on any machine outside a browser.

2. Node.js is single-threaded, that implements a concurrency model based on an event loop.
 It doesn’t block the main thread  execution thread instead registers a callback which allows the application
 to continue.

3. It means Node.js can handle concurrent operations without creating multiple
threads of execution so can scale pretty well.

 Following are the areas where it’s perfect to use Node.js.
I/O bound Applications
Data Streaming Applications
Data Intensive Real-time Applications (DIRT)
JSON APIs based Applications
Single Page Applications
At the same time, it’s not suitable for heavy applications involving more of CPU usage.
===
event loop-

1. The event loop gives Node the capability to handle highly concurrent requests while still running “single-threaded”.
2 .The event loop on every iteration looks if there’s something in the call stack, and executes it:
3.  when node receives any request it is placed in the call stack,  node js process the request and send it ot client ,
4. If the request is asynchronous or contains blocking io, event loop delegate it to worker thread and
thread pool via event que.
  Worker thread will prepare the response and send it back to event loop which then runs the callback function
  and sends the response to client.
5. The loop gives priority to the call stack, and it first processes everything it finds in the call stack, and once there’s
 nothing in there, it goes to pick up things in the message queue.
-----
  event loop checks “is the stack empty ?” If stack is  empty and Queue has some data,
  event loop will take the top most one from it and push it inside of stack for processing.
 Task of event loop is to check is there any item present in Queue and if Stack empty then push
 it on stack else wait for next tick ( Yes process.nextTick ).
 The increment that the event loop moves in is called a ‘tick’, and every time it
 ‘ticks’ it checks if the call stack is empty.

 1. The event loop on every iteration looks if there’s something in the call stack, and executes it:
 The event loop is the term given to the process of the waiting for the msg queue to receive a message
  synchronously. The increment that the event loop moves in is called a ‘tick’, and every time it
  ‘ticks’ it checks if the call stack is empty, if so , it adds the top function in the event queue
  to the call stack and executes it.
 ===

 Phases Overview
 1. timers:              this phase executes callbacks scheduled by setTimeout() and setInterval().
 2. pending callbacks:   executes I/O callbacks deferred to the next loop iteration.
 3. idle, prepare:       only used internally.
 4. poll:                retrieve new I/O events; execute I/O related callbacks (almost all with the exception of
                      close callbacks, the ones scheduled by timers, and setImmediate()); node will block here when appropriate.
 5. check:               setImmediate() callbacks are invoked here.
 6. close callbacks:     some close callbacks, e.g. socket.on('close', ...)

poll phase
 If the poll queue is empty, one of two more things will happen:

 If scripts have been scheduled by setImmediate(), the event loop will end the poll phase and continue
  to the check phase to execute those scheduled scripts.

 If scripts have not been scheduled by setImmediate(), the event loop will wait for callbacks to be
  added to the queue, then execute them immediately.

  Generally, as the code is executed, the event loop will eventually hit the poll phase where it will wait
  for an incoming connection, request, etc. However, if a callback has been scheduled with setImmediate()
  and the poll phase becomes idle, it will end and continue to the check phase rather than waiting for poll events.



timer function----
  What is the purpose of setTimeout function?

  The setTimeout(cb, ms) global function is used to run callback cb after at least ms milliseconds.
  The actual delay depends on external factors like OS timer granularity and system load. A timer
  cannot span more than 24.8 days.
  The time value represents the (minimum) delay after which the message will actually be pushed into the queue.

  This function returns an opaque value that represents the timer which can be used to clear the timer.
  What is the purpose of clearTimeout function?

  The clearTimeout( t ) global function is used to stop a timer that was previously created with
   setTimeout(). Here t is the timer returned by setTimeout() function.
  What is the purpose of setInterval function?
``
  var t = setInterval(() => {
    console.log('---------');
  }, 1000);
  var t1 = setTimeout(() => {
    clearInterval(t);
  }, 4000);
  clearTimeout(t1);


  The setInterval(cb, ms) global function is used to run callback cb repeatedly after at least ms
   milliseconds. The actual delay depends on external factors like OS timer granularity and system
    load. A timer cannot span more than 24.8 days.

  This function returns an opaque value that represents the timer which can be used to clear the
  timer using the function clearInterval(t).

  setImmediate-
  Any function passed as the setImmediate() argument is a callback that’s executed in the next
  iteration of the event loop.
  setImmediate() is designed to execute a script once the current poll phase completes.

  The main advantage to using setImmediate() over setTimeout() is setImmediate() will always be executed
  before any timers if scheduled within an I/O cycle, independently of how many timers are present.

  A setTimeout() callback with a 0ms delay is very similar to setImmediate().+
   The execution order will depend on
  various factors, but they will be both run in the next iteration of the event loop.

  setImmediate(() => {
    console.log('immediate');
  });
  if we run the following script which is not within an I/O cycle (i.e. the main module),
   the order in which the two timers are executed is non-deterministic, as it is bound by
   the performance of the process: print- timeout, immediate

   However, if you move the two calls within an I/O cycle, the immediate callback is always executed first:
   The main advantage to using setImmediate() over setTimeout() is setImmediate() will always be executed
   before any timers if scheduled within an I/O cycle, independently of how many timers are present.
   Browsers have timers. setTimeout() creates a timer, waits until it fires and then adds a task to the queue.
    It has the signature:

process.nextTick()
  A function passed to process.nextTick() is going to be executed on the current iteration of
  the event loop, after the current operation ends. This means it will always execute before setTimeout and
   setImmediate.

   This is because process.nextTick() is not technically part of the event loop. Instead, the nextTickQueue will be
    processed after the current operation is completed,
    regardless of the current phase of the event loop.
    Here, an  operation is defined as a transition from the underlying C/C++ handler, and handling the JavaScript
    that needs to be executed.

   all callbacks passed to process.nextTick() will be resolved before the event loop continues.
   This can create some bad situations because it allows you to "starve"/ freeze your I/O by making
    recursive process.nextTick() calls, which prevents the event loop from reaching the poll phase.
    Why use process.nextTick()?
  There are two main reasons:
  Allow users to handle errors, cleanup any then unneeded resources, or perhaps try the request again before the event loop continues.
  At times it's necessary to allow a callback to run after the call stack has unwound but before the event loop continues.
 ====
 "I/O" refers primarily to interaction with the system's disk and network supported by libuv.
 ===
 node js project structure =

controller layer
service layer
data layer

server -
    -app.js (server creating code and run migration code, app level middlewares)
    -routes.js
    -service
    -api - component wise folder index.js and controller.js
    -config- environment- development.js/production.js/test.js

storage - dbwise model and migration
sync - written schedulers using  cron jobs const cron = require('node-cron');
package.json
.gitignore
readme.md

Don’t put your business logic inside the controllers!! ☠️
You may be tempted to just use the express.js controllers to store the business logic of your application,
 but this quickly becomes spaghetti code, as soon as you need to write unit tests,
  you will end up dealing with complex mocks for req or res express.js objects.

F
  ====
  dependancy injection

  export default class UserService {
  constructor(userModel, companyModel, salaryModel){
    this.userModel = userModel;
    this.companyModel = companyModel;
    this.salaryModel = salaryModel;
  }
  getMyUser(userId){
    // models available throug 'this'
    const user = this.userModel.findById(userId);
    return user;
  }
}
--
import UserService from '../services/user';
import UserModel from '../models/user';
import CompanyModel from '../models/company';
const salaryModelMock = {
  calculateNetSalary(){
    return 42;
  }
}
const userServiceInstance = new UserService(userModel, companyModel, salaryModelMock);
const user = await userServiceInstance.getMyUser('12346');

==

It’s complicated to distingue when a response should be sent, and when to continue processing in ‘background’,
let’s say after the response is sent to the client.
 ===
worker threads-

Workers (threads) are useful for performing CPU-intensive JavaScript operations.
They will not help much with I/O-intensive work.
The worker_threads module enables the use of threads that execute JavaScript in parallel.:
worker_threads can share memory.

Worker threads have:

One process
Multiple threads
One event loop per thread
One JS Engine Instance per thread
One Node.js Instance per thread

What makes Worker Threads special:

ArrayBuffers-  to transfer memory from one thread to another
MessagePort- used for communicating between different threads. It can be used to transfer structured data, memory regions and
other MessagePorts between different Workers.
MessageChannel represents an asynchronous, two-way communications channel used for communicating between different threads.
SharedArrayBuffer- that will be accessible from either thread. It lets you share memory between threads (limited to binary data).
Atomics available, it lets you do some processes concurrently, more efficiently and allows you to implement conditions variables in JavaScript
WorkerData is used to pass startup data. An arbitrary JavaScript value that contains a clone of the data passed to this thread’s
Worker constructor. The data is cloned as if using postMessage

What is expected for Workers (hopefully):
1. Passing native handles around e.g. sockets, http request
2. Deadlock detection. Deadlock is a situation where a set of processes are blocked because each process is
 holding a resource and waiting for another resource acquired by some other process. Deadlock detention will
 be useful for Worker threads in this case.
3. More isolation, so if one process is affected, it won’t affect others.
====

https://nodesource.com/blog/worker-threads-nodejs/
https://nodejs.org/uk/docs/guides/dont-block-the-event-loop/ ****
worker pool thread pool
1. Node js uses Worker Pool to handle expensive i/o tasks like file I/O
2. Node uses the Event-Driven Architecture: it has an Event Loop for for the wxpected working of node js
and a Worker Pool for expensive tasks.
3. Node's Worker Pool is implemented in libuv library, which exposes a general task submission API.
4. Node uses the Worker Pool to handle "expensive" tasks. This includes I/O for which an operating system does
 not provide a non-blocking version, as well as particularly CPU-intensive tasks.
5. the Worker Pool uses a real queue whose entries are tasks to be processed.
   A Worker pops a task from this queue and works on it,
   and when finished the Worker raises an "At least one task is finished" event for the Event Loop.
6.  These are the Node module APIs that make use of this Worker Pool

 I/O-intensive
 DNS: dns.lookup(), dns.lookupService().
 File System: All file system APIs except fs.FSWatcher and those that are explicitly synchronous use libuv's threadpool.

 CPU-intensive
 Crypto: crypto.pbkdf2(), crypto.scrypt(), crypto.randomBytes(), crypto.randomFill(), crypto.generateKeyPair().
 Zlib: All zlib APIs except those that are explicitly synchronous use libuv's threadpool.

===
Web Workers
1. Using Web Workers enables you to offload an expensive operation to a separate thread of execution,
 freeing up the main thread to do other things.
2. The worker includes a separate message queue, event
 loop, and memory space independent from the original thread that instantiated it.
 3. Communication between the worker and the main thread is done via message passing, which looks very much like the
  traditional, evented code-examples we’ve already seen.
===
Q-2. What Are The Key Features Of Node.Js?

1.Asynchronous event driven IO helps concurrent request handling –
All APIs of Node.js are asynchronous. This feature means that if a Node receives a request for some
Input/Output operation, it will execute that operation in the background and continue with the
processing of other requests. Thus it will not wait for the response from the previous requests.

2.Fast in Code execution – Node.js uses the V8 JavaScript Runtime engine, the one which is used by
Google Chrome. Node has a wrapper over the JavaScript engine which makes the runtime engine much
faster and hence processing of requests within Node.js also become faster.

3.Single Threaded but Highly Scalable –
Node.js uses a single thread model for event looping. The response
from these events may or may not reach the server immediately. However, this does not block other
operations. Thus making Node.js highly scalable. Traditional servers create limited threads to handle
requests while Node.js creates a single thread that provides service to much larger numbers of such
requests.

4.Node.js library uses JavaScript
5. Does not block the main execution thread
====
When Should We Use Node.Js?
It’s ideal to use Node.js for developing streaming or event-based real-time applications that
require less CPU usage such as.
Chat applications.
Game servers.

Good For A Collaborative Environment.

Advertisement Servers.

Streaming Servers.
To summarize, it’s good to use Node.js, when you need high levels of concurrency but less amount of
dedicated CPU time.

Last but not the least, since Node.js uses JavaScript internally, so it fits best for building
client-side applications that also use JavaScript.
===
When To Not Use Node.Js?
However, we can use Node.js for a variety of applications. But it is a single threaded framework,
so we should not use it for cases where the application requires long processing time.
If the server is doing some calculation, it won’t be able to process any other requests.
 Hence, Node.js is best when processing needs less dedicated CPU time.
===
node modules-
1. Module in Node.js is a simple or complex functionality organized in single or multiple
JavaScript files which can be reused throughout the Node.js application.

2. Each module in Node.js has its own context, so it cannot interfere with other modules
or pollute global scope.
Also, each module can be placed in a separate .js file under a separate folder.

Node.js Module Types
Node.js includes three types of modules:

Core Modules
Local Modules
Third Party Modules

core modules-
http	-http module includes classes, methods and events to create Node.js http server.
url	-url module includes methods for URL resolution and parsing.
querystring	-querystring module includes methods to deal with query string.
path	-path module includes methods to deal with file paths.
fs	-fs module includes classes, methods, and events to work with file I/O.
util	-util module includes utility functions useful for programmers.

In order to use Node.js core or NPM modules, you first need to import it
using require() function as shown below.

Node.js Local Module
Local modules are modules created locally in your Node.js application.
These modules include different functionalities of your application in
separate files and folders. You can also package it and distribute it via NPM,
so that Node.js community can use it. For example, if you need to connect to MongoDB
and fetch data then you can create a module for it, which can be reused
in your application.
===
Q-17. What Is EventEmitter In Node.Js?
Answer.
1. Node.js core API is based on asynchronous event-driven architecture in which certain kind of
objects called emitters periodically emit events that cause listener objects to be called.
2. this objects that emit events are members of EventEmitter class.
3. EventEmitters provides multiple properties like “on” and “emit”. The “on” property is used
    to bind a function to the event and “emit” is used to fire an event.
4. Events module in Node.js allows us to create and handle custom events.
5. When the EventEmitter object emits an event, all of the functions attached to that specific
    event are called synchronously.
    =======
     All values returned by the called listeners are ignored and
    will be discarded.
6.The EventEmitter calls all listeners synchronously in the order in which they were registered.

    emitter.addListener(event, listener)
    	Adds a listener to the end of the listeners array for the specified event.
      No checks are made to see if the listener has already been added.

    emitter.on(event, listener)
    Adds a listener to the end of the listeners array for the specified event.
    No checks are made to see if the listener has already been added. It can also be called as an alias
    of emitter.addListener*

    emitter.emit * event[, arg1][, arg2][, ...] *
    Raise the specified events with the supplied arguments.

    emitter.once(event, listener)
    Adds a one time listener for the event. This listener is invoked only the next
    time the event is fired, after which it is removed.

    emitter.removeListener(event, listener)
    Removes a listener from the listener array for the specified event.
    Caution: changes array indices in the listener array behind the listener.

    emitter.removeAllListeners([event])
    Removes all listeners, or those of the specified event.

    emitter.setMaxListeners(n)
    	By default EventEmitters will print a warning if more than 10 listeners are
      added for a particular event.

    emitter.getMaxListeners()
    Returns the current maximum listener value for the emitter which is either
    set by emitter.setMaxListeners *n* or defaults to EventEmitter.defaultMaxListeners.

    emitter.listeners(event)
    Returns a copy of the array of listeners for the specified event.

    emitter.listenerCount(type)
    Returns the number of listeners listening to the type of event.

    const em  = new event.EventEmitter();
    //Subscribe FirstEvent
  em.addListener('FirstEvent', function (data, abc) {
    console.log('First subscriber: ' + data);
      console.log('----: ' + abc);
  });

  //Subscribe SecondEvent
  em.on('SecondEvent', function (data) {
      console.log('First subscriber: ' + data);
  });

  // Raising FirstEvent
  em.emit('FirstEvent', 'This is my first Node.js event emitter example.', 'my abc');

  // Raising SecondEvent
  em.emit('SecondEvent', 'This is my second Node.js event emitter example.');

========
Blocking vs non Blocking
Blocking

1. Blocking is when the execution of additional JavaScript in the Node.js
process must wait until a non-JavaScript operation completes.
2. This happens because the event loop is unable to continue running JavaScript
while a blocking operation is occurring.
3. A process is labeled blocked if it is not ready for execution but is instead
 waiting for an I/O event to take place. I/O events indicate progress or
 completion in an I/O operation, for example "resource available" or
 "write complete".
 4. Blocking methods execute synchronously and non-blocking methods execute
 asynchronously.

 5. Blocking call waits for the I/O operation to complete before returning.
  Its results are returned synchronously. Nothing else in that process
  takes place during the waiting.

  Non Blocking
  6. In contrast, non-blocking call returns
  immediately without results and uses alternate means to check for completion.
   Other processing can be done while waiting and the results are returned
   asynchronously. Node.js libraries and core api provide non-blocking calls
   that can be used to build performant applications. Such applications make
    use of I/O waiting time to serve other requests.

    Non-blocking functions are used in regards with I/O operations. They immediately respond with whatever data is
     available and keeps on running as per the requests. In case, any answer couldn’t be retrieved then the API returns
     immediately with an error
========
asynchronous vs non Blocking
  synchronous / asynchronous is to describe the relation between two modules.
  blocking / non-blocking is to describe the situation of one module.

  Asynchronous :
  1. The term itself defines that it is not synchronous. The architecture of asynchronous explains that the
   message sent will not give the reply on immediate basis just like we send the mail but do not get the reply on an
   immediate basis.
  2. It does not have any dependency or order. Hence improving the system efficiency and performance.
  3. The server stores the information and when the action is done it will be notified.

Non-Blocking:
1. Nonblocking immediately responses with whatever data available. Moreover, it does not block any execution and
keeps on running as per the requests. If an answer could not be retrieved than in those cases API returns
immediately with an error.
2. Nonblocking is mostly used with I/O(input/output). Node.js is itself based on nonblocking I/O model.
3. There are few ways of communication that a nonblocking I/O has completed.
The callback function is to be called when the operation is completed.
 Nonblocking call uses the help of javascript which provides a callback function.

---------
differnces-


1) Asynchronous does not respond immediately, While Nonblocking responds immediately if the data is available and
if not that simply returns an error.
2) Asynchronous improves the efficiency by doing the task fast as the response might come later, meanwhile,
can do complete other tasks.
Nonblocking does not block any execution and if the data is available it retrieves the information quickly.
3) Asynchronous is the opposite of synchronous while nonblocking I/O is the opposite of blocking.
They both are fairly similar but they are also different as asynchronous is used with a broader range of
operations while nonblocking is mostly used with I/O.
=====
how does node prevents blocking code??

By providing callback function. Callback function gets called whenever corresponding event triggered.
===
libraries used
in node

gulp
amqplib
aws-sdk
bunyan
cron
elasticsearch
joi
jsonwebtoken
lodash
moment
node-cron
pg
mssql
pg-copy-streams
s3-upload-stream
==
error first callback/errorback/errback
1. Most asynchronous methods exposed by the Node.js core API follow an idiomatic pattern
referred to as an error-first callback. With this pattern, a callback function is passed
to the method as an argument. When the operation either completes or an error is raised,
the callback function is called with the Error object (if any) passed as the first argument.
 If no error was raised, the first argument will be passed as null.

reason==
 Node.js relies on asynchronous code to stay fast, so having a dependable callback pattern is crucial.
  Without one, developers would be stuck maintaining different signatures and styles between each and every module.

is the first callback necessary argument?
 ===
http://book.mixu.net/node/ch7.html
Control flow functions ====
 A control flow function
 is a lightweight, generic piece of code which runs in between several asynchronous
  function calls and which take care of the necessary housekeeping to:

control the order of execution,
collect data,
limit concurrency and
call the next step in the program.

we can use this in
1: Series - an asynchronous for loop
2: Full parallel - an asynchronous, parallel for loop
3: Limited parallel - an asynchronous, parallel, concurrency limited for loop

Nest callbacks to get serial behavior.
Collocate method calls to get parallel behavior.
Use callbacks to untangle nested serial actions.
Use counters to know when groups of parallel actions are finished.
Use libraries like Combo to ease the pain.

====
The Child Processes Module

1. A child process is the creation of a parent process, which can be defined as the main process
 that creates child or subprocesses to perform certain operations.
 2. Each process can have many child processes but only one parent.
 3. A child process inherits most of its parent's attributes.
 4. Node.js, in its essence, is a single thread process. It does not expose child threads and thread
 management methods to the developer.
 5 Technically, Node.js does spawn child threads for certain
 tasks such as asynchronous I/O, but these run behind the scenes and do not execute any application
 JavaScript code, nor block the main event loop.
6. We can easily spin a child process using Node’s child_process module and those child processes
can easily communicate with each other with a messaging system.
7. The child_process module enables us to access Operating System functionalities
by running any system command inside a child process.

We can control that child process input stream, and listen to its output stream.
We can also control the arguments to be passed to the underlying OS command,
 and we can do whatever we want with that command’s output.

 There are four different ways to create a child process in Node: spawn(),
 fork(), exec(), and execFile.

 Node.js child_process.exec method
 The child_process.exec method runs a command in a console and buffers the output.

 Node.js child_process.spawn method
The child_process.spawn method launches a new process with a given command.

This method returns streams stdout & stderr and it is generally used when the process returns
 large amount of data.

 Node.js child_process.fork method
The child_process.fork method is a special case of the spawn to create Node processes.
This method returns object with a built-in communication channel in addition to having all
the methods in a normal ChildProcess instance.

differnce between spawn and fork

spawn
Spawn is a command designed to run system commands. When you run spawn, you send it a system
 command that will be run on its own process, but does not execute any further code within your
 node process. You can add listeners for the process you have spawned, to allow your code interact
  with the spawned process, but no new V8 instance is created(unless of course your command is
  another Node command, but in this case you should use fork!) and only one copy of your node
   module is active on the processor.

   When a spawn is created - It creates a streaming interfacee between parent and child process.
streaming interfacee means - buffering data in binary format

Fork is a special instance of spawn, that runs a fresh instance of the V8 engine.
Meaning, you can essentially create multiple workers, running on the exact same Node code base,
 or perhaps a different module for a specific task. This is most useful for creating a worker pool.
 While node's async event model allows a single core of a machine to be used fairly efficiently,
  it doesn't allow a node process to make use of multi core machines. Easiest way to accomplish
  this is to run multiple copies of the same program, on a single processor.

  When a fork is created - It creates a communication channel between parent and child process
communication channel means - messaging

spawn will be useful when you want to do continuous kind of operation like data read/write in stream

fork will be useful when you want to do messaging

spawn should be used for streaming big data/files/images FROM spawn process TO parent process

fork should be used for doing Json/Xml Data messaging .
===

36. Explain the purpose of ExpressJS package?
1. Express.js is a framework built on top of Node.js and it  facilitates the management of the
 flow of data between server and routes in the server-side applications.

  2. It is a lightweight and flexible framework that provides a wide range of features required
   for the web as well as mobile application development.
  3. Express.js is developed on the middleware module of Node.js called connect.
  4. The connect module further makes use of http module to communicate with Node.js.
5. The routing functions & framework let you get quickly to your business logic.

  Connect module in Node JS tool is extended to enable developers to connect to a variety of common web
  application used case features. They are defined as follows:-

1. HTML template engines
2. Various data formatting outputs
3. Routing system

===
Q-26. What Is Chaining Process In Node.Js?
Answer.
It’s an approach to connect the output of one stream to the input of another stream, thus creating a
chain
of multiple stream operations.
In chaining every method return the object, so that we can chain different calls in single line.

General Chaining:
    Functions may not belong to any single object.
Singleton Chaining:
    Created with object literal, every methods returns object
Instance Chaining:
    Created object with a constructor method and can have many instances
    Advantages of chaining:

    Reduces the headache of creating and maintaining the variables.
    Clean and intuitive code.
    Enforces functional approach.
==
    Q-24. Does Node.Js Support Multi-Core Platforms? And Is It Capable Of Utilizing All The Cores?
Answer.
Yes, Node.js would run on a multi-core system without any issue. But it is by default a
single-threaded application, so it can’t completely utilize the multi-core system.

However, Node.js can facilitate deployment on multi-core systems where it does use the additional
hardware. It packages with a Cluster module which is capable of starting multiple Node.js worker
processes that will share the same port.

Some of important properties of nodejs cluster :

a)isDead : Tells if a worker is dead or alive. It returns true if the worker is ended

b)isConnected : Tells if the worker is connected to it’s master

c)isMaster : tells if current process is master

d)isWorker : Tells if current process is worker

e)worker : Returns current working worker

f)workers : Returns all workers

g)id : Returns unique id for a worker

h)fork : Creates new worker from the master

i)disconnect  : Disconnects all workers

var numCPUs = os.cpus().length;
if (cluster.isMaster) {
  // Fork workers.
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('online', (worker) => {
    logger.info('worker is online : ', worker.id);
  });
  cluster.on('exit', (worker) => {
    logger.info(`worker ${worker.process.pid} died`);
    cluster.fork();
  });
} else {
  childProcess()
}

What Is <Package.Json>?
A package is:
  1. it is a plain JSON JavaScript Object Notation text file which contains all metadata information about
 Node.js Project or application.
2. This file should be present in the root directory of every Node.js Package or Module to describe its
metadata in JSON format.
3. The file is named as “package” because Node.js platform treats every feature as a separate component.
Node.js calls these as Package or Module.
Who Use It?
4. NPM (Node Package Manager) uses <package.json> file. It includes details of the Node.js application or
package. This file contains a no. of different directives or elements. These directives guide NPM,
 about how to handle a module or package.
5. has dependancies dev dependancies that the project required
6. can write run,test , build script
7. Project information like version , project name, author name
===
 Q-20. What Is NPM In Node.Js?
Answer.
NPM stands for Node Package Manager. It provides following two main functionalities.
1. It works as an Online repository for node.js packages/modules which are present at <nodejs.org>.
2. It works as Command line utility to install packages, do version management and dependency
 management of Node.js packages.
3. 800,000 code packages
4. Open-source developers use npm to share software
5. Many organizations also use npm to manage private development.
  npm can manage dependencies.
6. You can publish any directory from your computer as long as the directory has a package.json file.
===
REPL
1. A read–eval–print loop (REPL), also termed an interactive toplevel or language shell, is a
  simple, interactive computer programming environment that takes single user inputs
  (i.e., single expressions), evaluates (executes) them, and returns the result to the user; a
  program written in a REPL environment is executed piecewise

  The read function accepts an expression from the user, and parses it into a data structure in memory.
  The eval function takes this internal data structure and evaluates it.
  The print function takes the result yielded by eval, and prints it out to the user.
  The development environment then returns to the read state, creating a loop,
  which terminates when the program is closed.

  As a shell, a REPL environment allows users to access relevant features of an operating system
  in addition to providing access to programming capabilities.

  ===
  Q-19. List And Explain The Important REPL Commands?
  Answer.

  Following is the list of some of the most commonly used REPL commands.

  <.help> – It displays help for all the commands.
  <tab Keys> – It displays the list of all the available commands.
  <Up/Down Keys> – Its use is to determine what command was executed in REPL previously.
  <.save filename> – Save the current REPL session to a file.
  <.load filename> – To Load the specified file in the current REPL session.
  <ctrl + c> – used to Terminate the current command.
  <ctrl + c (twice)> – To Exit from the REPL.
  <ctrl + d> – This command perfoms Exit from the REPL.
  <.break> – It leads Exitting from multiline expression.
  <.clear> – Exit from multiline expression.
===
  What are Streams?
https://www.freecodecamp.org/news/node-js-streams-everything-you-need-to-know-c9141306be93/

  1. Streams are objects that let you read data from a source or write data to
  a destination in continuous fashion.
2. The difference is that streams might not be available all at once, and they don’t have to fit in memory.
This makes streams really powerful when working with large amounts of data, or data that’s
3. In Node.js, there are four types of streams −
coming from an external source one chunk at a time.
      Readable − Stream which is used for read operation.

      Writable − Stream which is used for write operation.

      Duplex − Stream which can be used for both read and write operation.

      Transform − A type of duplex stream where the output is computed based on input.
      A transform stream is basically a duplex stream that can be used to modify or transform the data as
       it is written and read.

        An example of that is the zlib.createGzip stream to compress the data using
       gzip. You can think of a transform stream as a function where the input is the writable stream part
        and the output is readable stream part. You might also hear transform streams referred to as
         “through streams.”

The pipe method returns the destination stream, which enabled us to do the chaining above. For streams a (readable), b and c (duplex),
and d (writable), we can:
      =========
      Differentiate between readFile vs createReadStream in Node.js?

Node.js provides two ways to read and execute files which are using readFile and CreateStream.

readFile() is a fully buffered process which returns the response only when the complete file is
 pushed into the buffer and is read. It is a memory intensive process and in case of large files,
  the processing can be very slow.

  Whereas createReadStream is a partially buffered which treats the entire process as an event series.
   The entire file is split into chunks which are then processed and sent back as a response one by one.
    Once done, they are finally removed from the buffer.
    Unlike readFile, createReadStream is really effective for the processing of the large files.
====
Q-13. Can You Create HTTP Server In Nodejs, Explain The Code Used For It?
Answer.
Yes, we can create HTTP Server in Node.js. We can use the <http-server> command to do so.

Following is the sample code.

var http = require('http');
var requestListener = function (request, response) {
response.writeHead(200, {'Content-Type': 'text/plain'});
response.end('Welcome Viewers\n');
}
var server = http.createServer(requestListener);
server.listen(8080); // The port where you want to start with.
==
How assert works in Node.js?
In Node.js, assert is used to write tests. It only provides feedback only when any of the running
test cases fails. This module gives you a set of assertion tests which are then used for testing invariants.
It is basically used internally by Node.js but using require(‘assert’) code, it can be used in other applications as well.
===
https://codeburst.io/javascript-unit-testing-using-mocha-and-chai-1d97d9f18e71
Testing in nodejs

The smallest parts of an application are called units, testing of those units to check whether it is fit for use or
 not is called unit testing.

assert module
The assert module provides a set of assertion functions for verifying invariants.
The module provides a recommended strict mode and a more lenient legacy mode.
deepEqual
Test Assertion
Assertion is an expression which helps system (Mocha in this case) to know code under test failed.
Assert’s job is to just throw an error when things are not correct or right.
Assert tests the expression and it does nothing when expression passes but throws exception in case of
 failure to tell the test framework about it.
We can just throw an exception to fail the test as well.

assert.strictEqual().
assert.Equal()

testing asynchronous function--
Mocha waits for the done() function to be get called to complete the test.
done();

Chai
Chai is BDD/TDD assertion library.
Can be paired with any javascript testing framework.
Assertion with Chai provides natural language assertions, expressive and readable style.

Assertion interfaces and styles
There are two popular way of assertion in Chai, expect and should
The expect interface provides function for assertion.
The should interface extends each object with a should property for assertion.
should property gets added to the Object.Prototype, so that all object can access it through prototype chain.
You can go through article JavaScript —

var assert = require('assert');
var {expect, should} = require('chai')

describe('Basic Mocha String Test', function () {
 it('should return number of charachters in a string', function () {
        assert.equal("Hello".length, 4);
    });
 it('should return first charachter of the string', function () {
        assert.equal("Hello".charAt(0), 'H');
    });
});


describe('ArrayCheck', () => {
  it('checks the array', () => {
    const test = productsController.checkArray([1, 3, 2], 3);
    assert.equal(test, true);
  })
})
describe('ArrayCheck1', () => {
  it('checks the array1', () => {
    const test = productsController.checkArray([1, 3, 2], 3);
    expect(test).to.be.true;
  })
})

describe('ArrayCheck2', () => {
  it('checks the array2', () => {
    const test = productsController.checkArray([1, 3, 2], 3);
    test.should.equal(true);
  })
})



assert=== helps to determine the status of the test, it determines failure of the test.
describe === is a function which holds the collection of tests. It takes two parameters,
 first one is the meaningful name to functionality under test and second one is the function which contains one
 or multiple tests. We can have nested describe as well.
it === is a function again which is actually a test itself and takes two parameters, first parameter is name to the
 test and second parameter is function which holds the body of the test.
===
Q-15. What Are Globals In Node.Js?
Answer.
There are three keywords in Node.js which constitute as Globals. These are Global, Process, and Buffer.

Global.
The Global keyword represents the global namespace object. It acts as a container for all other
<global> objects. If we type <console.log(global)>, it’ll print out all of them.
An important point to note about the global objects is that not all of them are in the global
 scope, some of them fall in the module scope. So, it’s wise to declare them without using the var
 keyword or add them to Global object.

Variables declared using the var keyword become local to the module whereas those declared without
it get subscribed to the global object.

Process.
The process object is the global object in Node. It can be accessed from anywhere;
it is an instance of  EventEmitter class. And each node application object is an instance of the
Process object.
Each Node.js has a set of built-in functionality, accessible through the global process object.

 The process object provides the standard input/output (stdio) streams
 stdin, stdout and stderr (as in C/C++) as in the following:

 stdin: a readable stream for reading input from the user.
 stdout: a writable stream, either synchrously or asynchronously.
 stderr: a blocking synchronous writable stream intended for error messages.

It primarily gives back the information about the application or the environment.

<process.execPath> – to get the execution path of the Node app.
<process.Version> – to get the Node version currently running.
<process.platform> – to get the server platform.

Some of the other useful Process methods are as follows.
process.pid - It's OS process ID.
process.title: By default a process title is NODE but you can change it.

<process.memoryUsage> – To know the memory used by Node application.
<process.NextTick> – To attach a callback function that will get called during the next loop.
It can cause a delay in executing a function.
The stdout or non-blocking function are: console.log, console.info, util.puts, util.print and Stderr.
====
Buffer.
The Buffer is a class in Node.js to handle binary data.
It represents a fixed-size chunk of memory (can’t be resized) allocated outside of the V8 JavaScript
engine.
 It is similar to a list of integers but
stores as a raw memory outside the V8 heap.

Buffers were introduced to help developers deal with binary data, in an ecosystem that traditionally
only dealt with strings rather than binaries.

 Buffer class is used because pure JavaScript is not compatible with binary data. So, when
  dealing with TCP streams or the file system, it’s necessary to handle octet streams

Buffers are deeply linked with streams. When a stream processor receives data faster than it can
digest, it puts the data in a buffer.

Buffer.from(), Buffer.alloc(memory in kb), Buffer.allocUnsafe()
const buffer = Buffer.from('heyuuu', 'ascii');

We can convert JavaScript string objects into Buffers. But it requires mentioning the encoding
type explicitly.

<ascii> – Specifies 7-bit ASCII data.
<utf8> – Represents multibyte encoded Unicode char set.
<utf16le> – Indicates 2 or 4 bytes, little endian encoded Unicode chars.
<base64> – Used for Base64 string encoding.
<hex> – Encodes each byte as two hexadecimal chars.
Here is the syntax to use the Buffer class.

deprecated
> var buffer = new Buffer(string, [encoding]);
use
> var buffer =buffer.from(string, [encoding]);

The above command will allocate a new buffer holding the string with <utf8> as the default encoding.
 However, if you like to write a <string> to an existing buffer object, then use the following line
 of code.
buffer.alloc(5);
Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled.

buffer.allocUnsafe(5);
 size <integer> The desired length of the new Buffer.
 Allocates a new Buffer of size bytes. If size is larger than buffer.constants.MAX_LENGTH or smaller than 0,
 ERR_INVALID_OPT_VALUE is thrown. A zero-length Buffer is created if size is 0.

> buffer.write(string)
This class also offers other methods like <readInt8> and <writeUInt8> that allows read/write from
 various types of data to the buffer.

===
Explain the reason as to why Express ‘app’ and ‘server’ must be kept separate.
Express ‘app’ and ‘server’ must be kept separate as by doing this, you will be separating the
 API declaration from the network related configuration which benefits in the below listed ways:

Keeping the API declaration separated from the network related configuration (port, protocol, etc)
allows testing the API in-process, without performing network calls, with all the benefits that it
brings to the table: fast testing execution and getting coverage metrics of the code.
It also allows deploying the same API under flexible and different network conditions. Bonus: better separation of
concerns and cleaner code.

var app = express();
app.use(bodyParser.json());
app.use("/api/events", events.API);
app.use("/api/forms", forms);
Server network declaration should reside in /bin/www:

var app = require('../app');
var http = require('http');
//Get port from environment and store in Express
var port = normalizePort(process.env.PORT || '8000');
app.set('port', port);
//Create HTTP server.
var server = http.createServer(app);
 ===
diff between exports and module.exports

module is a plain JavaScript object with an exports property. exports is a plain JavaScript variable
 that happens to be set to module.exports. At the end of your file, node.js will basically 'return'
 module.exports to the require function.
 Initially, exports and module.exports point at the same empty object.

so if you attach property a to an exports it will be automatically attach to module.exports because of
the same refernce

so then exports and module.exports are the same object.

but, what if you want to export a function, or a string, or a unicorn?

This is when the difference between exports and module.exports is important.

If you remember nothing else from this article, remember this:

module.exports wins

What this means is that whatever object module.exports is assigned to is the object that is exported from your module.

If you want to export a function from your module and you assign it to exports and not module.exports then this happens:

then your code will return {} object as module.exports = {} not exports = function.

====
export vs export defaults

Named Export: (export)
With named exports, one can have multiple named exports per file. Then import the specific exports they want
surrounded in braces. The name of imported module has to be the same as the name of the exported module.

Default Export: (export default)
One can have only one default export per file. When we import we have to specify a name and import like:

// import
import MyDefaultComponent from "./MyDefaultExport";
// export
const MyComponent = () => {}
export default MyComponent;
The naming of import is completely independent in default export and we can use any name we like.
===
Function composition
Function composition is the process of combining two or more functions to produce a new function.
Composing functions together is like snapping together a series of pipes for our data to flow through.

const add = (a, b) => a + b;
const mult = (a, b) => a * b;
add(2, mult(3, 5))

const users = [
  { name: "Jeff", age: 14 },
    { name: "Jack", age: 18 },
    { name: "Milady", age: 22 },
]
const filter = (cb, arr) => arr.filter(cb);
const map = (cb, arr) => arr.map(cb);

map(u => u.name, filter(u => u.age >= 18, users)); //["Jack", "Milady"]
===
Q3: Explain what is Reactor Pattern in Node.js?

Reactor Pattern is an idea of non-blocking I/O operations in Node.js.
 This pattern provides a handler(in case of Node.js, a callback function) that is associated with each I/O operation.
  When an I/O request is generated, it is submitted to a demultiplexer.

This demultiplexer is a notification interface that is used to handle concurrency in non-blocking I/O mode.
it collects every request in form of an event and queues each event in a queue.
Thus, the demultiplexer provides  the Event Queue.

At the same time, there is an Event Loop which iterates over the items in the Event Queue.
Every event has a callback function associated with it, and that callback function is invoked when
the Event Loop iterates.
===
Explain libuv.
Libuv is a multi-platform support library of Node.js which majorly is used for asynchronous I/O.
It was primarily developed for Node.js,  with time it is popularly practiced with other systems
like as Luvit, pyuv, Julia, etc. Libuv is basically an abstraction around libev/ IOCP depending
on the platform, providing users an API based on libev. A few of the important features of libuv are:

Full-featured event loop backed
File system events
Asynchronous file & file system operations
Asynchronous TCP & UDP sockets
Child processes

===

What function are arguments available to Express JS route handlers?
Answer:
The arguments which are available to an Express JS route handler-function are-

• Req – the request object
• Res – the response object
• Next (optional) – a function that is employed to pass management to 1 of the following
 route handlers.

The third argument is optional and should be omitted, however, in some cases, it’s helpful wherever
there’s a series of handlers and management will be passed to 1 of the following route handlers
skipping this one.
===
6. How to allow CORS in Express JS? Explain with an example?

Cross-Origin Resource Sharing (CORS) is a mechanism that uses additional HTTP headers to tell a
browser to let a web application running at one origin (domain) have permission to access selected
resources from a server at a different origin.

In order to permit CORS in Express.js, add the subsequent code in server.js:
For Example –
app.all(‘*’, function(req, res, next) {
res.set(‘Access-Control-Allow-Origin’, ‘*’);
res.set(‘Access-Control-Allow-Methods’, ‘GET, POST, DELETE, PUT’);
res.set(‘Access-Control-Allow-Headers’, ‘X-Requested-With, Content-Type’);
if (‘OPTIONS’ == req.method) return res.send(200);
next();
});


set headers
res.set({
  'Content-Type': 'text/plain',
  'Content-Length': '123',
  'ETag': '12345'
})
app.use((req, res, next) => {
    res.append('Access-Control-Allow-Origin', ['*']);
    res.append('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE');
    res.append('Access-Control-Allow-Headers', 'Content-Type');
    next();
});

====

uestion 13. What Is The Parameter “next” Used For In Express?

Answer :
Next simply allows the next route handler in line to handle the request.

app.get('/userdetails/:id?', function(req, res, next){
 });

req and res which represent the request and response objects

nextIt passes control to the next matching route.

In this case you need both the middleware functions to be invoked.
So, the only way you reach the second middleware function is by calling next();
====

Question 17. How To Redirect 404 Errors To A Page In Expressjs?
Answer :

In server.js add the following code to redirect 404 errors back to a page in our ExpressJS App:

/* Define fallback route */
app.use(function(req, res, next) {
    res.status(404).json({errorCode: 404, errorMsg: "route not found"});
});

===
Q.3) What is Scaffolding in Express JS?
Scaffolding is creating the skeleton structure of application

There are 2 way to do this:

Express application generator
Yeoman
====
Q.6) What is routing and how routing works in Express.js?
Routing refers to determining how an application responds to a client request to a particular endpoint, which is a URI
(or path) and
a specific HTTP request method (GET, POST, and so on).
Each route can have one or more handler functions, which are executed when the route is matched.
====
index.js
app.use(require('./api'));
-----
const express = require('express');

const Router = express.Router({mergeParams : true});

Router.delete('/api/category/:id', CategoryController.deleteCategory);
Router.get('/api/categories', CategoryController.getAllCategories);

module.exports = Router;
----
Preserve the req.params values from the parent router. If the parent
and the child have conflicting param names, the child’s value take precedence.
--
Route Syntax:
codesource
app.METHOD(PATH, HANDLER)
Where:

app is an instance of express.
METHOD is an HTTP request method, in lowercase.
PATH is a path on the server.⭐
HANDLER is the function executed when the route is matched.
#Example:

codesource
app.get('/', function (req, res) {
  res.send('Express Js Interview Questions')
})

Dynamic routing and how it works in Express.js?
When someone pass parameters in URL i.e. Parametrized URL,
this routing phenomenon is called dynamic
 routing.

codesource
var express = require('express'),
app = express();


const Router = express.Router({mergeParams : true});

app.get('/article/:id', function(req , res){
  res.render('article' + req.params.id);
})
In above example: id is a parameters, which can be different for different calls.
===
Q.7) What is middleware in Express Js?
In short, middleware is a subset of chained functions that run between the client request and the server answer.
Middleware functions are functions that have access to the request object (req),
the response object (res), and the next middleware function in the application’s
request-response cycle. The next middleware function is commonly denoted by a variable
 named next.
 The next function is a function in the Express router which, when invoked,
 executes the middleware succeeding the current middleware.
 As name suggests it comes in middle of something and that is request and response cycle
Middleware has access to request and response object
Middleware has access to next function of request-response life cycle.

Middleware functions can perform the following tasks:
Execute any code.
Make changes to the request and the response objects.
End the request-response cycle.
Call the next middleware in the stack.

If the current middleware function does not end the request-response cycle,
it must call next() to pass
 control to the next middleware function. Otherwise, the request will be left hanging.

An Express application can use the following types of middleware:
Application-level middleware
Router-level middleware
Error-handling middleware
Built-in middleware
Third-party middleware
1. Application-level middleware
This kind of middleware method is bind to the app Object using app.use() method.

//This middleware will execute for each route.
app.use(function (req, res, next) {
  console.log('Current Time:', Date.now())
  next()
})
2. Router-level middleware:
Router-level middleware works in the same way as application-level middleware, except it is bound to
an instance of express.Router()

3. Built-in middleware:
Starting with version 4.x, Express no longer depends on Connect.

Express has the following built-in middleware functions:

express.static serves static assets such as HTML files, images, and so on.
express.json parses incoming requests with JSON payloads. NOTE: Available with Express 4.16.0+
express.urlencoded parses incoming requests with URL-encoded payloads.
NOTE: Available with Express 4.16.0+

4. Third-party middleware:
There are a number of third party middleware, such as body-parser cookie-parser, mongoose and so on.
===
To handle HTTP POST request in Express.js version 4 and above, you need to install middleware
module called body-parser, body-parser extract the entire body portion of an incoming request stream
 and exposes it on req.body, The middleware was a part of Express.js earlier but now you have to install it separately.

These can be installed by using command:
codesource
>> npm install MODULE_NAME
And they can be loaded using requires and used later.

#Example:
codesource
var bodyParser = require('body-parser');
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: false }))
====
bodyParser
parsing - analyse (a string or text) into logical syntactic components.

Node.js body parsing middleware.

Parse incoming request bodies in a middleware before your handlers, available under the req.body property.
====
app.set(name, value)
Assigns setting name to value. You may store any value that you want, but certain names can be used
to configure the behavior of the server. These special names are listed in the app settings table.

Calling app.set('foo', true) for a Boolean property is
the same as calling app.enable('foo'). Similarly, calling app.set('foo', false) for a Boolean property is the
same as calling app.disable('foo').
===
req.body
Contains key-value pairs of data submitted in the request body. By default, it is undefined,
and is populated when you use body-parsing middleware such as express.json() or express.urlencoded().
---
req.params
This property is an object containing properties mapped to the named route “parameters”.
For example, if you have the route /user/:name, then the “name” property is available as
req.params.name. This object defaults to {}.
===
req.query
This property is an object containing a property for each query string parameter
in the route. If there is no query string, it is the empty object, {}.
// GET /search?q=tobi+ferret
console.dir(req.query.q)

===
   Dependency vs Dev Dependency & peerDependaancy?

   The difference between these two, is that devDependencies are modules which are only required
   during development,
    while dependencies are modules which are also required at runtime.
     npm install --save-dev, instead of just an npm install --save.
     Some good examples of when to install devDependencies would be Nodemon, Babel, ESLint,Gulp, and
     testing frameworks like Chai, Mocha, Enzyme,

     peerdependancies -
     in case u have dependancies which ur app required is of other version and the
     same dependancy is required or used by another module but of diffrent versions
     then we define peerDependancy.
=====
orm-
1. orm  is a programming technique for converting data between incompatible type systems
using object-oriented programming languages.
2. This creates, in effect, a "virtual object database" that can be used, accessed and modified from within
the programming language.
3. ORM hides and encapsulates change in the data source itself, so that when data sources or their APIs
change, only ORM needs to
 change to keep up—not the applications that use ORM to insulate themselves from this kind of effort.

node orm-
Sequelize
NOde-Orm2
bookshelf
objection.js
caminte.js
sequelize support PostgreSQL, MySQL, MariaDB, SQLite and MSSQL
mongoose for MongoDB

why to use/advantage
 we dont need to do database language specific query to perform db operation
 it hides the database asbstraction so we can sweetch betwwen the orm supproted db
 Depending on the ORM you get a lot of advanced features out of the box, such as
  support for transactions, connection pooling, migrations, seeds, streams, and all sorts of other goodies.

ORM solutions are useful to facilitate data-driven API development.
Users have concrete needs which drive the data model of an application.
In legacy development, this data architecture is typically implemented and version controlled
 using database scripts such as SQL scripts.
  A separate library is then used for the server application to execute CRUD actions on the database.

ORMs work as a high-level API to execute CRUD, and these days quality ORMs also allow us to
initialize the data through code. Complex data manipulation, cleaning and so on, is often easier
in code. While dedicated Extract, Transform and Load (ETL) tools exist, the same ETL tasks can
be easily implemented in ORM.
===
   migrations
      Using migrations allows you to easily and safely update your tables and database.
      Just like you use Git / SVN
      to manage changes in your source code, you can use migrations to keep track of changes
      to the database
      With migrations you can transfer your existing database into another state and vice versa:
      Those state
      transitions are saved in migration files, which describe how to get to the new state
      and how to revert the changes in order to get back to the old state.

      Model-
      Sequelize will only use Model files, it's the table representation. On the other hand,
      the migration file
      is a change in that model or more specifically that table, used by CLI.
      Treat migrations like a commit or a
      log for some change in database

      Suppose we want to insert some data into a few tables by default.
       If we follow up on previous example we can consider
       creating a demo user for User table.

   Seeders
   To manage all data migrations you can use seeders. Seed files are some change in data that
    can be used to
    populate database table with sample data or test data.
===
how to connect to the database

sequelize
const sequelize = new Sequelize('database', 'username', 'password', {
  host: 'localhost',
  dialect: /* one of 'mysql' | 'mariadb' | 'postgres' | 'mssql' */
});
----
postgres
var pg = require('pg');
var client = new pg.Client(conString);
client.connect();
----
mysql
let mysql = require('mysql');

let connection = mysql.createConnection({
    host: 'localhost',
    user: 'root',
    password: '',
    database: 'todoapp'
});
connection.connect(function(err) {
  if (err) {
    return console.error('error: ' + err.message);
  }

  console.log('Connected to the MySQL server.');
});

===
    Error Handling
    Catching uncaught exceptions
If an uncaught exception gets thrown during the execution of your program, your program will crash.
To solve this, you listen for the uncaughtException event on the process object:

process.on('uncaughtException', (err) => {
    console.error('There was an uncaught error', err);
    process.exit(1) //mandatory (as per the Node docs)
})

using error catching middleware
app.use((err, req, res, next) => {
if(err) {
return throw err;
}
next();
})

Error handling with async/await

async function someFunction() {
  try {
    await someOtherFunction()
  }
  catch (err) {
    console.error(err.message)
  }
}

try {
  //lines of code
} catch (e) {

}
===
Anatomy of an error object
The first argument for a native error object is its description. The description is the human-readable
 string of your error object. It’s what pops up in your console when something goes awry.

Second error objects also have a name property, which is the computer-readable part of the object.
 When you use the native error object, the name property defaults to the generic “Error.” , but you
  can create your own. The best way to do this is by extending the native error object like so:

  throw new Error('database failed to connect');

  When JavaScript finds a throw keyword, the first thing it does is stop dead in its tracks,
  which prevents any more functions from running. By stopping like this, it mitigates the risk of any
  further errors occurring and helps us not to get the state of our program all twisted.

With the program halted, JavaScript will begin to look back up the daisy chain of functions that were
called in order to reach a catch statement. This daisy chain is called the call stack (don’t worry—we’ll
 get to the call stack soon). The nearest catch that JavaScript finds is where the thrown exception will
 emerge. If no try/catch is found, the exception throws, and the Node.js process will exit, causing the server to restart.
===
http://www.javascriptkit.com/javatutors/trycatch2.shtml
Error vs Throw New Error()

The Error constructor creates an error object. Instances of Error objects are thrown when runtime errors occur.
The Error object can also be used as a base object for user-defined exceptions. See below for standard built-in error types.

Error is functional, new Error is a constructor. both works same

When Error is called as a function rather than as a constructor, it creates and initialises a new Error object.
Thus the function call Error(…) is equivalent to the object creation expression new Error(…) with the same arguments

When Error is used like a function -- without new, it will return an Error object. Therefore, a mere call to
Error will produce the same output that constructing an Error object via the new keyword would.

named and ananomous function = >
// Anonymous function
const one = () => {};

// Anonymous functions
const two = function () {};

// Explicitly named function
const three = function explicitFunction() {};

===
To catch or not to catch promises?
At this point, you might be wondering whether adding a catch to your promises is optional. Yes it’s optional,
but you should always provide a catch handler.

Why? Because there are many ways your asynchronous calls can fail. Our code might timeout, it could have network issues,
or there might be a hardware failure. For all of these reasons, you should always instruct
your program what to do in the case of a promise failure.

Remember the golden rule: always handle promise rejections.

Try/catch is by default synchronous. That means that if an asynchronous function throws an error in a synchronous
try/catch block, no error throws.


v8 engine-
In order to obtain speed, V8 translates JavaScript code into more efficient machine code instead of using an interpreter.
It compiles JavaScript code into machine code at execution by implementing a JIT (Just-In-Time) compiler like a lot of
modern JavaScript engines such as SpiderMonkey or Rhino (Mozilla) are doing.
 The main difference with V8 is that it doesn’t produce bytecode or any intermediate code.
Instead of using a dictionary-like data structure for storing object properties and doing a dynamic lookup
to resolve the property location (like most JavaScript engines do), V8 creates hidden classes, at runtime,
in order to have an internal representation of the type system and to improve the property access time.
V8 has two compilers!

A “Full” Compiler that can generate good code for any JavaScript: good but not great JIT code.
The goal of this compiler is to generate code quickly. To achieve its goal, it doesn’t do any type analysis
and doesn’t know anything about types. Instead, it uses an Inline Caches or “IC” strategy to refine knowledge
about types while the program runs. IC is very efficient and brings about 20 times speed improvment.

An Optimizing Compiler that produces great code for most of the JavaScript language. It comes later and
re-compiles hot functions. The optimizing compiler takes types from the Inline Cache and make decisions about
how to optimize the code better. However, some language features are not supported yet like try/catch blocks for instance.
 (The workaround for try/catch blocks is to write the “non stable” code in a function and call the function in the try block)

Code optimization: V8 also supports de-optimization: the optimizing compiler makes optimistic assumptions from the Inline
Cache about the different types, de-optimization comes if these assumptions are invalid. For example, if a hidden
class generated was not the one expected, V8 throws away the optimized code and comes back to the Full Compiler
to get types again from the Inline Cache. This process is slow and should be avoided by trying to not change functions
after they are optimized.
====
what us hidden classes & whats the advantage.

https://richardartoul.github.io/jekyll/update/2015/04/26/hidden-classes.html

Javascript is dynamically type language. while accessing the objects and its properties the v8
engine doesnt follow the disctionary approach, i,e looking for the objects and prperties in the storage
beacuse object properties can be created and destroyed at run time.

for each object creation and for each property it creates the hidden class and set the offset
of each property.
if any property is added to the object the new hidden class is created with the incremental offset and
old object hidden class is updated with the transition path to the new.

v8 engine makes use of inline cashing while compiling the code.
v8 eng stores the information about the type of object that is passed
in the recent method calls and use that information to make assumption for the same
type of objct that will be passed in the future.
if v8 makes good assumption about the object it makes use of stored information from
the previous lookup hidden classes.

Whenever a method is called on a specific object, the V8 engine has to perform a lookup
 to that objects hidden class to determine the offset for accessing a specific property.
  After two successful calls of the same method to the same hidden class, V8 omits the hidden
  class lookup and simply adds the offset of the property to the object pointer itself.
   For all future calls of that method, the V8 engine assumes that the hidden class hasn’t
    changed, and jumps directly into the memory address for a specific property using the
     offsets stored from previous lookups; this greatly increases execution speed.

 Event Loop executes the JavaScript callbacks registered for events, and is also responsible for
 fulfilling non-blocking asynchronous requests like network I/O.
=======
microservicess -
Microservices solve these challenges of monolithic systems by being as modular as possible.
In the simplest form, they help build an application as a suite of small services, each
running in its own process and are independently deployable. These services may be written
in different programming languages and may use different data storage techniques. While this
results in the development of systems that are scalable and flexible, it needs a dynamic
makeover
==
7.How to enable debugging in express app?

Answer:
In different operative Systems, we’ve got following commands:

On UNIX operating system the command would be as follows:

$ DEBUG=express:* node index.js

On Windows the command would be:

set DEBUG=express:* & node index.js
From Webstrome IDE


====
Question 8. How To Output Pretty Html In Express.js?

Answer :

app.set('view options', { pretty: true });

===
How To Get The Full Url In Express?

Answer :

var port = req.app.settings.port || cfg.port;

res.locals.requested_url = req.protocol + '://' + req.host  + ( port == 80 || port == 443 ? '' : ':'+port ) + req.path;

===

Question 10. How To Remove Debugging From An Express App?

Answer :

var io = require('socket.io').listen(app, { log: false });
io.set('log level', 1);

====
Question 12. How To Download A File?

Answer :

app.get('/download', function(req, res){
  var file = __dirname + '/download-folder/file.txt';
  res.download(file);
});

====
How can you make sure your dependencies are safe?
When writing Node.js applications, ending up with hundreds or even thousands of dependencies can easily happen.
For example, if you depend on Express, you depend on 27 other modules directly, and of course on those dependencies'
as well, so manually checking all of them is not an option!

The only option is to automate the update / security audit of your dependencies. For that there are free and paid options:

npm outdated
Trace by RisingStack
NSP
GreenKeeper
Snyk
======
connection pooling

In software engineering, a connection pool is a cache of database connections maintained so that the connections can be
reused when future requests
 to the database are required. Connection pools are used to enhance the performance of executing commands on a database.
 Opening and maintaining
 a database connection for each user, especially requests made to a dynamic database-driven website application, is costly
  and wastes resources.
 In connection pooling, after a connection is created, it is placed in the pool and it is used again so that a new connection
 does not have to be
 established. If all the connections are being used, a new connection is made and is added to the pool. Connection pooling also
  cuts down on the
 amount of time a user must wait to establish a connection to the database.

var mysql = require('mysql');

var pool  = mysql.createPool({
    host     : 'localhost',
    user     : 'root',
    password : 'root',
    database : 'guess'
});
var getConnection = function(callback) {
    pool.getConnection(function(err, connection) {
        callback(err, connection);
    });
};

module.exports = getConnection;
exports.pool = pool;

---postgres
var pg = require('pg')
var PGUSER = 'deploy'
var PGDATABASE = 'oscpushserver'
var config = {
  user: PGUSER, // name of the user account
  database: PGDATABASE, // name of the database
  max: 10, // max number of clients in the pool
  idleTimeoutMillis: 30000
}

var pool = new pg.Pool(config);

module.exports = pool;

---
const pool = require('../path/to/database.js');

router.get(function(req, res, next) {
  pool.connect(function (err, client, done) {
    if (err) throw new Error(err);
    var ageQuery = format('SELECT * from push_table WHERE seq_id = 1')
    client.query(ageQuery, function (err, result) {
      if (err) throw new Error(err);
      res.json(result.rows[0]);
    })
  });
});
